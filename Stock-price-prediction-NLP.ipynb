{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Prediction using Reddit News Headlines <br\\>\n",
    "## Byungsu Jung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from subprocess import check_output\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1989.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.535445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label\n",
       "count  1989.000000\n",
       "mean      0.535445\n",
       "std       0.498867\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Stock-Market-Prediction/stocknews/Combined_News_DJIA.csv')\n",
    "train = data[data['Date'] <= '2015-01-01']\n",
    "test = data[data['Date'] >= '2014-12-31']\n",
    "# combine all the headlines into one string for each dates\n",
    "# To lowercase\n",
    "trainheadlines = []\n",
    "testheadlines = []\n",
    "for row in range(0,len(train.index)):\n",
    "    trainheadlines.append(' '.join(str(x).lower() for x in train.iloc[row,2:27]))\n",
    "for row in range(0, len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x).lower() for x in test.iloc[row, 2:27]))\n",
    "\n",
    "# Data not skwed.    \n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I wish to predict up and down of stock price based on news headlines, <br\\> \n",
    "I have assumed that a single word (i.e. unigram ) will not contain enough information of sentiment of word towards up and down of stock price. <br\\>\n",
    "First we will naively verify my claim by calculating accuracy score of each n-grams on LogisticRegression and use the best n-gram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing using Tf-Idf and n-gram <br\\>\n",
    "### Purpose: To find the best n-gram for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram train set shape:  (1611, 1952)\n",
      "bigram train set shape:  (1611, 657)\n",
      "unigram test set shape:  (379, 1952)\n",
      "bigram test set shape:  (379, 657)\n"
     ]
    }
   ],
   "source": [
    "# Use logistic regression to choose naively choose best n-gram\n",
    "# We will also use Tf-idf in addition to n-gram to give a score to the words from headlines to identify which word or \n",
    "# words best represents a set of headlines, and use that score of each word or words as input to the\n",
    "\n",
    "unigramVectorizer =  TfidfVectorizer( min_df=0.03, max_df=0.97, max_features = 200000, ngram_range = (1, 1))\n",
    "bigramVectorizer =  TfidfVectorizer( min_df=0.03, max_df=0.97, max_features = 200000, ngram_range = (2, 2))\n",
    "\n",
    "uniTrain = unigramVectorizer.fit_transform(trainheadlines)\n",
    "\n",
    "biTrain = bigramVectorizer.fit_transform(trainheadlines)\n",
    "\n",
    "uniTest = unigramVectorizer.transform(testheadlines)\n",
    "\n",
    "biTest = bigramVectorizer.transform(testheadlines)\n",
    "print(\"unigram train set shape: \", uniTrain.shape)\n",
    "print(\"bigram train set shape: \", biTrain.shape)\n",
    "print(\"unigram test set shape: \", uniTest.shape)\n",
    "print(\"bigram test set shape: \", biTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram accuracy score:  0.46965699208443273\n",
      "Bigram accuracy score:  0.5725593667546174\n"
     ]
    }
   ],
   "source": [
    "biLogisticR = LogisticRegression()\n",
    "uniLogisticR = LogisticRegression()\n",
    "biLogisticR.fit(biTrain, train['Label'])\n",
    "uniLogisticR.fit(uniTrain, train['Label'])\n",
    "# Accuracy score of two\n",
    "uni_accuracy = accuracy_score(test['Label'], uniLogisticR.predict(uniTest))\n",
    "bi_accuracy = accuracy_score(test['Label'], biLogisticR.predict(biTest))\n",
    "print(\"Unigram accuracy score: \", uni_accuracy)\n",
    "print(\"Bigram accuracy score: \", bi_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show highest coefficient and corresponding feature\n",
    "def head_tail(vectorizer, model):\n",
    "    features = vectorizer.get_feature_names()\n",
    "    coeff = list(model.coef_)[0]\n",
    "    df = pd.DataFrame({\"features\": features,\n",
    "                      \"coefficient\": coeff})\n",
    "    df = df.sort_values('coefficient', ascending=False)\n",
    "    result_df = pd.concat([df.head(), df.tail()])\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1.264377</td>\n",
       "      <td>set to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.259669</td>\n",
       "      <td>and other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1.216202</td>\n",
       "      <td>right to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1.166895</td>\n",
       "      <td>likely to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.128663</td>\n",
       "      <td>after the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>-1.098193</td>\n",
       "      <td>fire on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-1.128193</td>\n",
       "      <td>around the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>-1.144952</td>\n",
       "      <td>phone hacking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-1.146688</td>\n",
       "      <td>up in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>-1.393351</td>\n",
       "      <td>the country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficient       features\n",
       "411     1.264377         set to\n",
       "31      1.259669      and other\n",
       "391     1.216202       right to\n",
       "276     1.166895      likely to\n",
       "14      1.128663      after the\n",
       "131    -1.098193        fire on\n",
       "40     -1.128193     around the\n",
       "366    -1.144952  phone hacking\n",
       "597    -1.146688          up in\n",
       "452    -1.393351    the country"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_tail(bigramVectorizer,biLogisticR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, bigram had accuracy greater than random, the words(features) are not yet intuitive.<br\\>\n",
    "It looks like two word is better than one word, but still not enough to hold meaningful intuition. Let's try to combine uni, bi and tri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5171503957783641"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigramVectorizer = TfidfVectorizer(min_df=0.03, max_df=0.97, max_features = 200000, ngram_range = (1, 3))\n",
    "triTrain = trigramVectorizer.fit_transform(trainheadlines)\n",
    "triTest = trigramVectorizer.transform(testheadlines)\n",
    "triLogisticR = LogisticRegression()\n",
    "triLogisticR.fit(triTrain, train['Label'])\n",
    "tri_accuracy = accuracy_score(test['Label'], triLogisticR.predict(triTest))\n",
    "tri_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1.264377</td>\n",
       "      <td>set to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.259669</td>\n",
       "      <td>and other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1.216202</td>\n",
       "      <td>right to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1.166895</td>\n",
       "      <td>likely to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.128663</td>\n",
       "      <td>after the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>-1.098193</td>\n",
       "      <td>fire on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-1.128193</td>\n",
       "      <td>around the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>-1.144952</td>\n",
       "      <td>phone hacking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-1.146688</td>\n",
       "      <td>up in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>-1.393351</td>\n",
       "      <td>the country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficient       features\n",
       "411     1.264377         set to\n",
       "31      1.259669      and other\n",
       "391     1.216202       right to\n",
       "276     1.166895      likely to\n",
       "14      1.128663      after the\n",
       "131    -1.098193        fire on\n",
       "40     -1.128193     around the\n",
       "366    -1.144952  phone hacking\n",
       "597    -1.146688          up in\n",
       "452    -1.393351    the country"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_tail(trigramVectorizer,triLogisticR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the results above, we procede our stock price up and down prediction with **bi-gram** tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic regression with bigram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, We already used Logistic Regression with bi-gram without any hyperparameter tuning. <br\\>\n",
    "The follwoing is confusion matrix with accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram accuracy score:  0.5725593667546174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 73, 114],\n",
       "       [ 48, 144]], dtype=int64)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Bigram accuracy score: \", bi_accuracy)\n",
    "confusion_matrix(test['Label'],biLogisticR.predict(biTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tunig on Test data(No validation set) <br\\>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_c:  0.4910000000000003\n",
      "best_acc:  0.5883905013192612\n",
      "best_model:  LogisticRegression(C=0.4910000000000003, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 56, 131],\n",
       "       [ 25, 167]], dtype=int64)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1828ab8ba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1828b4774e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "best_c = 0\n",
    "best_acc = 0\n",
    "best_model = None\n",
    "data_acc = []\n",
    "for i in np.arange(0.1, 1.0, 0.001):\n",
    "  model = LogisticRegression(C = i)\n",
    "  model.fit(biTrain, train['Label'])\n",
    "  \n",
    "  y_train_pred = model.predict(biTrain)\n",
    "  train_acc = accuracy_score(train['Label'], y_train_pred)\n",
    "  \n",
    "  y_test_pred = model.predict(biTest)\n",
    "  test_acc = accuracy_score(test['Label'], y_test_pred)\n",
    "  \n",
    "  data_acc.append({'C': i, 'train accuracy': train_acc, \n",
    "               'test accuracy': test_acc})\n",
    "  if(test_acc > best_acc):\n",
    "    best_acc = test_acc\n",
    "    best_c = i\n",
    "    best_model = model\n",
    "data_acc = pd.DataFrame(data_acc)\n",
    "sns.relplot(kind='line', x='C', y='train accuracy', data=data_acc)\n",
    "sns.relplot(kind='line', x='C', y='test accuracy', data=data_acc)\n",
    "print(\"best_c: \", best_c)\n",
    "print(\"best_acc: \", best_acc)\n",
    "print(\"best_model: \", best_model)\n",
    "confusion_matrix(test['Label'],best_model.predict(biTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above is not quite regularized since it tested it's hyperparameters on test dataset, which make the model overfit to the test data. We will improve this by using cross validation and using validation set to test hyper parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the visualization best hyperparameter C, which is inverse of regularization strength. Now with this idea, let's peform GRID SEARCH of range from 0.4 to 0.6 for each 0.001 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1001 candidates, totalling 3003 fits\n",
      "Accuracy Score : 0.575197889182058\n",
      "Precision Score : 0.5543859649122806\n",
      "Recall Score : 0.8229166666666666\n",
      "F1 Score : 0.6624737945492662\n",
      "best model: LogisticRegression(C=0.549499999999989, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 3003 out of 3003 | elapsed:   17.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 60, 127],\n",
       "       [ 34, 158]], dtype=int64)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_values = {'penalty': ['l2'],'C':np.arange(0.45, 0.55, 0.0001)}\n",
    "grid_clf_acc = GridSearchCV(LogisticRegression(), param_grid = grid_values, verbose=1, cv=3)\n",
    "grid_clf_acc.fit(biTrain, train['Label'])\n",
    "\n",
    "#Predict values based on new parameters\n",
    "y_pred_acc = grid_clf_acc.predict(biTest)\n",
    "\n",
    "# New Model Evaluation metrics \n",
    "print('Accuracy Score : ' + str(accuracy_score(test['Label'],y_pred_acc)))\n",
    "print('Precision Score : ' + str(precision_score(test['Label'],y_pred_acc)))\n",
    "print('Recall Score : ' + str(recall_score(test['Label'],y_pred_acc)))\n",
    "print('F1 Score : ' + str(f1_score(test['Label'],y_pred_acc)))\n",
    "print('best model: ' + str(grid_clf_acc.best_estimator_))\n",
    "#Logistic Regression (Grid Search) Confusion matrix\n",
    "confusion_matrix(test['Label'],y_pred_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see decrease in accuray by 0.01 but this is acceptable because this model is no longer overfit to test data. Now, let this logistic regression accuracy be our baseline for the accuracy of futher prediction by other classifiers. <br/>\n",
    "Let's try Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base RandomForest Accuracy:  0.5224274406332454\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "base_randomForest=RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "#Train the model using the training sets y_pred=base_randomForest.predict(X_test)\n",
    "base_randomForest.fit(biTrain,train['Label'])\n",
    "y_pred = base_randomForest.predict(biTest)\n",
    "base_randomForest_acc = accuracy_score(test['Label'],y_pred)\n",
    "print(\"Base RandomForest Accuracy: \", rf_clf_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple randomfrest classifier whoed 0.52 accuracy, which is still worse than our baseline.<br/> \n",
    "Let's do radom search to narrow down the hyperparameter space to improve the accuracy by hyperparameter tuning later in Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], dtype=object),\n",
      " 'max_features': ['sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': array([100, 200, 300, 400, 500, 600, 700, 800, 900]),\n",
      " 'random_state': [1]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = np.arange(100, 1000, 100)\n",
    "# Number of features to consider at /3every split\n",
    "max_features = ['sqrt'] # auto is using all features, sqrt is usually good for classification\n",
    "# Maximum number of levels in tree\n",
    "max_depth = np.arange(10, 110, 10)\n",
    "max_depth = np.append(max_depth,None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'random_state': [1]}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': array([100, 200, 300, 400, 500, 600, 700, 800, 900]), 'max_features': ['sqrt'], 'max_depth': array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], dtype=object), 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False], 'random_state': [1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=1)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier()\n",
    "randomForest_random = RandomizedSearchCV(estimator = randomForest, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=1, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "randomForest_random.fit(biTrain, train['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's checkout best estimator of RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=30, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=4, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
      "            oob_score=False, random_state=1, verbose=0, warm_start=False)\n",
      "0.5356200527704486\n"
     ]
    }
   ],
   "source": [
    "# Best parameters from ransom search\n",
    "print(randomForest_random.best_estimator_)\n",
    "print(accuracy_score(test['Label'], randomForest_random.predict(biTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's use this values to tune hyperparameters more precisesly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Grid and Grid-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 882 candidates, totalling 2646 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 36.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 53.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 72.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2646 out of 2646 | elapsed: 81.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'bootstrap': [True], 'max_depth': array([30, 40, 50, 60, 70, 80, 90]), 'max_features': ['sqrt', 219], 'min_samples_leaf': [3, 4, 5], 'min_samples_split': [8, 10, 12], 'n_estimators': array([300, 400, 500, 600, 700, 800, 900]), 'random_state': [1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = randomForest_random.best_estimator_.n_features_\n",
    "max_feature_by3 = n_features // 3\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': np.arange(20, 51, 10),\n",
    "    'max_features': ['sqrt', max_feature_by3],\n",
    "    'min_samples_leaf': [4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': np.arange(300, 1000, 100),\n",
    "    'random_state': [1]\n",
    "}\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 1)\n",
    "grid_search.fit(biTrain,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 576 out of 576 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'bootstrap': [True], 'max_depth': array([20, 30, 40, 50]), 'max_features': ['sqrt', 219], 'min_samples_leaf': [4, 5], 'min_samples_split': [8, 10, 12], 'n_estimators': array([400, 450, 500, 550]), 'random_state': [1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = randomForest_random.best_estimator_.n_features_\n",
    "max_feature_by3 = n_features // 3\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': np.arange(20, 51, 10),\n",
    "    'max_features': ['sqrt', max_feature_by3],\n",
    "    'min_samples_leaf': [4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': np.arange(400, 600, 50),\n",
    "    'random_state': [1]\n",
    "}\n",
    "# Instantiate the grid search model\n",
    "grid_search2 = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 1)\n",
    "grid_search2.fit(biTrain,train['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will definitely compare accuray of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=60, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=12,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5329815303430079"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test['Label'],grid_search.predict(biTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "best_grid_search = grid_search.best\n",
    "# Pull out one tree from the forest\n",
    "tree = best_grid_search.estimators_[5]\n",
    "\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_422 (Dense)            (None, 8)                 5264      \n",
      "_________________________________________________________________\n",
      "dropout_279 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_411 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_423 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_280 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_412 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_424 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_413 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,345\n",
      "Trainable params: 5,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/1\n",
      "1288/1288 [==============================] - 11s 9ms/step - loss: 0.6935 - acc: 0.5116 - val_loss: 0.6908 - val_acc: 0.5604\n",
      "379/379 [==============================] - 0s 239us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_425 (Dense)            (None, 16)                10528     \n",
      "_________________________________________________________________\n",
      "dropout_281 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_414 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_426 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_282 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_415 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_427 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_416 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10,817\n",
      "Trainable params: 10,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/1\n",
      "1288/1288 [==============================] - 10s 8ms/step - loss: 0.6941 - acc: 0.4837 - val_loss: 0.6922 - val_acc: 0.5480\n",
      "379/379 [==============================] - 0s 226us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_428 (Dense)            (None, 24)                15792     \n",
      "_________________________________________________________________\n",
      "dropout_283 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_417 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_429 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_284 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_418 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_430 (Dense)            (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "activation_419 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 16,417\n",
      "Trainable params: 16,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/1\n",
      "1288/1288 [==============================] - 11s 8ms/step - loss: 0.6923 - acc: 0.5179 - val_loss: 0.6883 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 261us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_431 (Dense)            (None, 32)                21056     \n",
      "_________________________________________________________________\n",
      "dropout_285 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_420 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_432 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_286 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_421 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_433 (Dense)            (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_422 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 22,145\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/1\n",
      "1288/1288 [==============================] - 12s 9ms/step - loss: 0.6915 - acc: 0.5349 - val_loss: 0.6898 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 171us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_434 (Dense)            (None, 40)                26320     \n",
      "_________________________________________________________________\n",
      "dropout_287 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_423 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_435 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_288 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_424 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_436 (Dense)            (None, 1)                 41        \n",
      "_________________________________________________________________\n",
      "activation_425 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,001\n",
      "Trainable params: 28,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/1\n",
      "1288/1288 [==============================] - 12s 9ms/step - loss: 0.6919 - acc: 0.5148 - val_loss: 0.6883 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 187us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_437 (Dense)            (None, 48)                31584     \n",
      "_________________________________________________________________\n",
      "dropout_289 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_426 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_438 (Dense)            (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dropout_290 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_427 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_439 (Dense)            (None, 1)                 49        \n",
      "_________________________________________________________________\n",
      "activation_428 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33,985\n",
      "Trainable params: 33,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/1\n",
      "1288/1288 [==============================] - 12s 9ms/step - loss: 0.6927 - acc: 0.5194 - val_loss: 0.6887 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 226us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_440 (Dense)            (None, 56)                36848     \n",
      "_________________________________________________________________\n",
      "dropout_291 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_429 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_441 (Dense)            (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dropout_292 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_430 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_442 (Dense)            (None, 1)                 57        \n",
      "_________________________________________________________________\n",
      "activation_431 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,097\n",
      "Trainable params: 40,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/1\n",
      "1288/1288 [==============================] - 13s 10ms/step - loss: 0.6920 - acc: 0.5295 - val_loss: 0.6909 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 232us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_443 (Dense)            (None, 64)                42112     \n",
      "_________________________________________________________________\n",
      "dropout_293 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_432 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_444 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_294 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_433 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_445 (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_434 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 46,337\n",
      "Trainable params: 46,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/1\n",
      "1288/1288 [==============================] - 13s 10ms/step - loss: 0.6924 - acc: 0.5179 - val_loss: 0.6889 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 316us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_446 (Dense)            (None, 8)                 5264      \n",
      "_________________________________________________________________\n",
      "dropout_295 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_435 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_447 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_296 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_436 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_448 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_437 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,345\n",
      "Trainable params: 5,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/2\n",
      "1288/1288 [==============================] - 13s 10ms/step - loss: 0.6938 - acc: 0.5101 - val_loss: 0.6893 - val_acc: 0.5604\n",
      "Epoch 2/2\n",
      "1288/1288 [==============================] - 0s 324us/step - loss: 0.6880 - acc: 0.5582 - val_loss: 0.6868 - val_acc: 0.5635\n",
      "379/379 [==============================] - 0s 282us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_449 (Dense)            (None, 16)                10528     \n",
      "_________________________________________________________________\n",
      "dropout_297 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_438 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_450 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_298 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_439 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_451 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_440 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10,817\n",
      "Trainable params: 10,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/2\n",
      "1288/1288 [==============================] - 12s 9ms/step - loss: 0.6912 - acc: 0.5365 - val_loss: 0.6890 - val_acc: 0.5511\n",
      "Epoch 2/2\n",
      "1288/1288 [==============================] - 0s 328us/step - loss: 0.6872 - acc: 0.5388 - val_loss: 0.6878 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 242us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_452 (Dense)            (None, 24)                15792     \n",
      "_________________________________________________________________\n",
      "dropout_299 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_441 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_453 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_300 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_442 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_454 (Dense)            (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "activation_443 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 16,417\n",
      "Trainable params: 16,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/2\n",
      "1288/1288 [==============================] - 12s 9ms/step - loss: 0.6908 - acc: 0.5342 - val_loss: 0.6894 - val_acc: 0.5511\n",
      "Epoch 2/2\n",
      "1288/1288 [==============================] - 0s 324us/step - loss: 0.6864 - acc: 0.5450 - val_loss: 0.6887 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 263us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_455 (Dense)            (None, 32)                21056     \n",
      "_________________________________________________________________\n",
      "dropout_301 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_444 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_456 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_302 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_445 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_457 (Dense)            (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_446 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 22,145\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/2\n",
      "1288/1288 [==============================] - 12s 9ms/step - loss: 0.6924 - acc: 0.5264 - val_loss: 0.6896 - val_acc: 0.5480\n",
      "Epoch 2/2\n",
      "1288/1288 [==============================] - 1s 483us/step - loss: 0.6873 - acc: 0.5427 - val_loss: 0.6878 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 253us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_458 (Dense)            (None, 40)                26320     \n",
      "_________________________________________________________________\n",
      "dropout_303 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_447 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_459 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_304 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_448 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_460 (Dense)            (None, 1)                 41        \n",
      "_________________________________________________________________\n",
      "activation_449 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,001\n",
      "Trainable params: 28,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/2\n",
      "1288/1288 [==============================] - 12s 9ms/step - loss: 0.6926 - acc: 0.5186 - val_loss: 0.6896 - val_acc: 0.5511\n",
      "Epoch 2/2\n",
      "1288/1288 [==============================] - 0s 375us/step - loss: 0.6864 - acc: 0.5474 - val_loss: 0.6885 - val_acc: 0.5542\n",
      "379/379 [==============================] - 0s 276us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_461 (Dense)            (None, 48)                31584     \n",
      "_________________________________________________________________\n",
      "dropout_305 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_450 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_462 (Dense)            (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dropout_306 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_451 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_463 (Dense)            (None, 1)                 49        \n",
      "_________________________________________________________________\n",
      "activation_452 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33,985\n",
      "Trainable params: 33,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/2\n",
      "1288/1288 [==============================] - 14s 11ms/step - loss: 0.6920 - acc: 0.5148 - val_loss: 0.6898 - val_acc: 0.5511\n",
      "Epoch 2/2\n",
      "1288/1288 [==============================] - 0s 367us/step - loss: 0.6832 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 234us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_464 (Dense)            (None, 56)                36848     \n",
      "_________________________________________________________________\n",
      "dropout_307 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_453 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_465 (Dense)            (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dropout_308 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_454 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_466 (Dense)            (None, 1)                 57        \n",
      "_________________________________________________________________\n",
      "activation_455 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,097\n",
      "Trainable params: 40,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/2\n",
      "1288/1288 [==============================] - 12s 9ms/step - loss: 0.6921 - acc: 0.5233 - val_loss: 0.6887 - val_acc: 0.5511\n",
      "Epoch 2/2\n",
      "1288/1288 [==============================] - 1s 661us/step - loss: 0.6830 - acc: 0.5419 - val_loss: 0.6876 - val_acc: 0.5480\n",
      "379/379 [==============================] - 0s 245us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_467 (Dense)            (None, 64)                42112     \n",
      "_________________________________________________________________\n",
      "dropout_309 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_456 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_468 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_310 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_457 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_469 (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_458 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 46,337\n",
      "Trainable params: 46,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/2\n",
      "1288/1288 [==============================] - 14s 11ms/step - loss: 0.6922 - acc: 0.5225 - val_loss: 0.6883 - val_acc: 0.5511\n",
      "Epoch 2/2\n",
      "1288/1288 [==============================] - 1s 610us/step - loss: 0.6840 - acc: 0.5435 - val_loss: 0.6873 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 295us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_470 (Dense)            (None, 8)                 5264      \n",
      "_________________________________________________________________\n",
      "dropout_311 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_459 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_471 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_312 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_460 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_472 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_461 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,345\n",
      "Trainable params: 5,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/3\n",
      "1288/1288 [==============================] - 15s 11ms/step - loss: 0.6927 - acc: 0.5225 - val_loss: 0.6914 - val_acc: 0.5511\n",
      "Epoch 2/3\n",
      "1288/1288 [==============================] - 0s 317us/step - loss: 0.6880 - acc: 0.5435 - val_loss: 0.6892 - val_acc: 0.5511\n",
      "Epoch 3/3\n",
      "1288/1288 [==============================] - 1s 438us/step - loss: 0.6854 - acc: 0.5396 - val_loss: 0.6889 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 279us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_473 (Dense)            (None, 16)                10528     \n",
      "_________________________________________________________________\n",
      "dropout_313 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_462 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_474 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_314 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_463 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_475 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_464 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10,817\n",
      "Trainable params: 10,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/3\n",
      "1288/1288 [==============================] - 13s 10ms/step - loss: 0.6922 - acc: 0.5194 - val_loss: 0.6903 - val_acc: 0.5511\n",
      "Epoch 2/3\n",
      "1288/1288 [==============================] - 0s 317us/step - loss: 0.6867 - acc: 0.5435 - val_loss: 0.6897 - val_acc: 0.5511\n",
      "Epoch 3/3\n",
      "1288/1288 [==============================] - 0s 311us/step - loss: 0.6811 - acc: 0.5575 - val_loss: 0.6897 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 229us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_476 (Dense)            (None, 24)                15792     \n",
      "_________________________________________________________________\n",
      "dropout_315 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_465 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_477 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_316 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_466 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_478 (Dense)            (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "activation_467 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 16,417\n",
      "Trainable params: 16,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/3\n",
      "1288/1288 [==============================] - 14s 11ms/step - loss: 0.6921 - acc: 0.5171 - val_loss: 0.6878 - val_acc: 0.5511\n",
      "Epoch 2/3\n",
      "1288/1288 [==============================] - 0s 368us/step - loss: 0.6849 - acc: 0.5388 - val_loss: 0.6858 - val_acc: 0.5511\n",
      "Epoch 3/3\n",
      "1288/1288 [==============================] - 1s 399us/step - loss: 0.6740 - acc: 0.5582 - val_loss: 0.6844 - val_acc: 0.5542\n",
      "379/379 [==============================] - 0s 366us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_479 (Dense)            (None, 32)                21056     \n",
      "_________________________________________________________________\n",
      "dropout_317 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_468 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_480 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_318 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_469 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_481 (Dense)            (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_470 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 22,145\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/3\n",
      "1288/1288 [==============================] - 14s 11ms/step - loss: 0.6930 - acc: 0.5233 - val_loss: 0.6896 - val_acc: 0.5511\n",
      "Epoch 2/3\n",
      "1288/1288 [==============================] - 1s 421us/step - loss: 0.6865 - acc: 0.5411 - val_loss: 0.6887 - val_acc: 0.5511\n",
      "Epoch 3/3\n",
      "1288/1288 [==============================] - 1s 591us/step - loss: 0.6805 - acc: 0.5559 - val_loss: 0.6887 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 287us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_482 (Dense)            (None, 40)                26320     \n",
      "_________________________________________________________________\n",
      "dropout_319 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_471 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_483 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_320 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_472 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_484 (Dense)            (None, 1)                 41        \n",
      "_________________________________________________________________\n",
      "activation_473 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,001\n",
      "Trainable params: 28,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/3\n",
      "1288/1288 [==============================] - 13s 10ms/step - loss: 0.6919 - acc: 0.5287 - val_loss: 0.6885 - val_acc: 0.5511\n",
      "Epoch 2/3\n",
      "1288/1288 [==============================] - 1s 389us/step - loss: 0.6844 - acc: 0.5411 - val_loss: 0.6877 - val_acc: 0.5511\n",
      "Epoch 3/3\n",
      "1288/1288 [==============================] - 0s 379us/step - loss: 0.6763 - acc: 0.5404 - val_loss: 0.6864 - val_acc: 0.5542\n",
      "379/379 [==============================] - 0s 245us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_485 (Dense)            (None, 48)                31584     \n",
      "_________________________________________________________________\n",
      "dropout_321 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_474 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_486 (Dense)            (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dropout_322 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_475 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_487 (Dense)            (None, 1)                 49        \n",
      "_________________________________________________________________\n",
      "activation_476 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33,985\n",
      "Trainable params: 33,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/3\n",
      "1288/1288 [==============================] - 15s 12ms/step - loss: 0.6915 - acc: 0.5311 - val_loss: 0.6878 - val_acc: 0.5511\n",
      "Epoch 2/3\n",
      "1288/1288 [==============================] - 1s 463us/step - loss: 0.6826 - acc: 0.5435 - val_loss: 0.6861 - val_acc: 0.5511\n",
      "Epoch 3/3\n",
      "1288/1288 [==============================] - 1s 464us/step - loss: 0.6719 - acc: 0.5497 - val_loss: 0.6837 - val_acc: 0.5542\n",
      "379/379 [==============================] - 0s 271us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_488 (Dense)            (None, 56)                36848     \n",
      "_________________________________________________________________\n",
      "dropout_323 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_477 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_489 (Dense)            (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dropout_324 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_478 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_490 (Dense)            (None, 1)                 57        \n",
      "_________________________________________________________________\n",
      "activation_479 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,097\n",
      "Trainable params: 40,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/3\n",
      "1288/1288 [==============================] - 13s 10ms/step - loss: 0.6932 - acc: 0.4915 - val_loss: 0.6908 - val_acc: 0.5511\n",
      "Epoch 2/3\n",
      "1288/1288 [==============================] - 1s 426us/step - loss: 0.6862 - acc: 0.5551 - val_loss: 0.6899 - val_acc: 0.5542\n",
      "Epoch 3/3\n",
      "1288/1288 [==============================] - 1s 428us/step - loss: 0.6731 - acc: 0.5839 - val_loss: 0.6900 - val_acc: 0.5542\n",
      "379/379 [==============================] - 0s 258us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_491 (Dense)            (None, 64)                42112     \n",
      "_________________________________________________________________\n",
      "dropout_325 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_480 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_492 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_326 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_481 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_493 (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_482 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 46,337\n",
      "Trainable params: 46,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/3\n",
      "1288/1288 [==============================] - 13s 10ms/step - loss: 0.6931 - acc: 0.5225 - val_loss: 0.6894 - val_acc: 0.5511\n",
      "Epoch 2/3\n",
      "1288/1288 [==============================] - 1s 508us/step - loss: 0.6838 - acc: 0.5450 - val_loss: 0.6882 - val_acc: 0.5573\n",
      "Epoch 3/3\n",
      "1288/1288 [==============================] - 1s 516us/step - loss: 0.6676 - acc: 0.6079 - val_loss: 0.6866 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 276us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_494 (Dense)            (None, 8)                 5264      \n",
      "_________________________________________________________________\n",
      "dropout_327 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_483 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_495 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_328 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_484 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_496 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_485 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,345\n",
      "Trainable params: 5,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/4\n",
      "1288/1288 [==============================] - 14s 11ms/step - loss: 0.6917 - acc: 0.5388 - val_loss: 0.6901 - val_acc: 0.5511\n",
      "Epoch 2/4\n",
      "1288/1288 [==============================] - 0s 362us/step - loss: 0.6891 - acc: 0.5396 - val_loss: 0.6893 - val_acc: 0.5511\n",
      "Epoch 3/4\n",
      "1288/1288 [==============================] - 0s 337us/step - loss: 0.6838 - acc: 0.5396 - val_loss: 0.6887 - val_acc: 0.5511\n",
      "Epoch 4/4\n",
      "1288/1288 [==============================] - 0s 348us/step - loss: 0.6801 - acc: 0.5396 - val_loss: 0.6874 - val_acc: 0.5511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s 289us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_497 (Dense)            (None, 16)                10528     \n",
      "_________________________________________________________________\n",
      "dropout_329 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_486 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_498 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_330 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_487 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_499 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_488 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10,817\n",
      "Trainable params: 10,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/4\n",
      "1288/1288 [==============================] - 13s 10ms/step - loss: 0.6925 - acc: 0.5272 - val_loss: 0.6889 - val_acc: 0.5573\n",
      "Epoch 2/4\n",
      "1288/1288 [==============================] - 0s 333us/step - loss: 0.6866 - acc: 0.5427 - val_loss: 0.6873 - val_acc: 0.5511\n",
      "Epoch 3/4\n",
      "1288/1288 [==============================] - 0s 326us/step - loss: 0.6798 - acc: 0.5582 - val_loss: 0.6862 - val_acc: 0.5542\n",
      "Epoch 4/4\n",
      "1288/1288 [==============================] - 0s 331us/step - loss: 0.6717 - acc: 0.5846 - val_loss: 0.6864 - val_acc: 0.5449\n",
      "379/379 [==============================] - 0s 247us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_500 (Dense)            (None, 24)                15792     \n",
      "_________________________________________________________________\n",
      "dropout_331 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_489 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_501 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_332 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_490 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_502 (Dense)            (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "activation_491 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 16,417\n",
      "Trainable params: 16,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/4\n",
      "1288/1288 [==============================] - 13s 10ms/step - loss: 0.6923 - acc: 0.5179 - val_loss: 0.6899 - val_acc: 0.5511\n",
      "Epoch 2/4\n",
      "1288/1288 [==============================] - 0s 338us/step - loss: 0.6878 - acc: 0.5396 - val_loss: 0.6886 - val_acc: 0.5511\n",
      "Epoch 3/4\n",
      "1288/1288 [==============================] - 0s 332us/step - loss: 0.6815 - acc: 0.5435 - val_loss: 0.6885 - val_acc: 0.5511\n",
      "Epoch 4/4\n",
      "1288/1288 [==============================] - 0s 329us/step - loss: 0.6740 - acc: 0.5543 - val_loss: 0.6875 - val_acc: 0.5449\n",
      "379/379 [==============================] - 0s 258us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_503 (Dense)            (None, 32)                21056     \n",
      "_________________________________________________________________\n",
      "dropout_333 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_492 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_504 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_334 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_493 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_505 (Dense)            (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_494 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 22,145\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/4\n",
      "1288/1288 [==============================] - 13s 10ms/step - loss: 0.6916 - acc: 0.5373 - val_loss: 0.6898 - val_acc: 0.5511\n",
      "Epoch 2/4\n",
      "1288/1288 [==============================] - 1s 427us/step - loss: 0.6870 - acc: 0.5450 - val_loss: 0.6887 - val_acc: 0.5573\n",
      "Epoch 3/4\n",
      "1288/1288 [==============================] - 1s 447us/step - loss: 0.6774 - acc: 0.5675 - val_loss: 0.6883 - val_acc: 0.5449\n",
      "Epoch 4/4\n",
      "1288/1288 [==============================] - 1s 408us/step - loss: 0.6611 - acc: 0.6382 - val_loss: 0.6902 - val_acc: 0.5294\n",
      "379/379 [==============================] - 0s 266us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_506 (Dense)            (None, 40)                26320     \n",
      "_________________________________________________________________\n",
      "dropout_335 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_495 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_507 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_336 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_496 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_508 (Dense)            (None, 1)                 41        \n",
      "_________________________________________________________________\n",
      "activation_497 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,001\n",
      "Trainable params: 28,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/4\n",
      "1288/1288 [==============================] - 14s 11ms/step - loss: 0.6932 - acc: 0.5280 - val_loss: 0.6886 - val_acc: 0.5511\n",
      "Epoch 2/4\n",
      "1288/1288 [==============================] - 1s 431us/step - loss: 0.6848 - acc: 0.5419 - val_loss: 0.6875 - val_acc: 0.5511\n",
      "Epoch 3/4\n",
      "1288/1288 [==============================] - 1s 438us/step - loss: 0.6737 - acc: 0.5683 - val_loss: 0.6874 - val_acc: 0.5511\n",
      "Epoch 4/4\n",
      "1288/1288 [==============================] - 1s 427us/step - loss: 0.6522 - acc: 0.6623 - val_loss: 0.6884 - val_acc: 0.5542\n",
      "379/379 [==============================] - 0s 271us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_509 (Dense)            (None, 48)                31584     \n",
      "_________________________________________________________________\n",
      "dropout_337 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_498 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_510 (Dense)            (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dropout_338 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_499 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_511 (Dense)            (None, 1)                 49        \n",
      "_________________________________________________________________\n",
      "activation_500 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33,985\n",
      "Trainable params: 33,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/4\n",
      "1288/1288 [==============================] - 14s 11ms/step - loss: 0.6914 - acc: 0.5450 - val_loss: 0.6868 - val_acc: 0.5511\n",
      "Epoch 2/4\n",
      "1288/1288 [==============================] - 1s 439us/step - loss: 0.6834 - acc: 0.5411 - val_loss: 0.6852 - val_acc: 0.5480\n",
      "Epoch 3/4\n",
      "1288/1288 [==============================] - 1s 421us/step - loss: 0.6717 - acc: 0.5536 - val_loss: 0.6845 - val_acc: 0.5604\n",
      "Epoch 4/4\n",
      "1288/1288 [==============================] - 1s 431us/step - loss: 0.6427 - acc: 0.6568 - val_loss: 0.6859 - val_acc: 0.5449\n",
      "379/379 [==============================] - 0s 295us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_512 (Dense)            (None, 56)                36848     \n",
      "_________________________________________________________________\n",
      "dropout_339 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_501 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_513 (Dense)            (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dropout_340 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_502 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_514 (Dense)            (None, 1)                 57        \n",
      "_________________________________________________________________\n",
      "activation_503 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,097\n",
      "Trainable params: 40,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/4\n",
      "1288/1288 [==============================] - 15s 11ms/step - loss: 0.6911 - acc: 0.5380 - val_loss: 0.6880 - val_acc: 0.5511\n",
      "Epoch 2/4\n",
      "1288/1288 [==============================] - 1s 410us/step - loss: 0.6807 - acc: 0.5536 - val_loss: 0.6872 - val_acc: 0.5511\n",
      "Epoch 3/4\n",
      "1288/1288 [==============================] - 1s 428us/step - loss: 0.6644 - acc: 0.5963 - val_loss: 0.6903 - val_acc: 0.4985\n",
      "Epoch 4/4\n",
      "1288/1288 [==============================] - 1s 494us/step - loss: 0.6250 - acc: 0.6949 - val_loss: 0.6958 - val_acc: 0.5325\n",
      "379/379 [==============================] - 0s 253us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_515 (Dense)            (None, 64)                42112     \n",
      "_________________________________________________________________\n",
      "dropout_341 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_504 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_516 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_342 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_505 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_517 (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_506 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 46,337\n",
      "Trainable params: 46,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/4\n",
      "1288/1288 [==============================] - 14s 11ms/step - loss: 0.6915 - acc: 0.5318 - val_loss: 0.6887 - val_acc: 0.5511\n",
      "Epoch 2/4\n",
      "1288/1288 [==============================] - 1s 494us/step - loss: 0.6797 - acc: 0.5481 - val_loss: 0.6894 - val_acc: 0.5666\n",
      "Epoch 3/4\n",
      "1288/1288 [==============================] - 1s 646us/step - loss: 0.6587 - acc: 0.6382 - val_loss: 0.6865 - val_acc: 0.5480\n",
      "Epoch 4/4\n",
      "1288/1288 [==============================] - 1s 698us/step - loss: 0.6086 - acc: 0.7337 - val_loss: 0.6947 - val_acc: 0.5542\n",
      "379/379 [==============================] - 0s 397us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_518 (Dense)            (None, 8)                 5264      \n",
      "_________________________________________________________________\n",
      "dropout_343 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_507 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_519 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_344 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_508 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_520 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_509 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,345\n",
      "Trainable params: 5,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/5\n",
      "1288/1288 [==============================] - 15s 12ms/step - loss: 0.6923 - acc: 0.5233 - val_loss: 0.6910 - val_acc: 0.5511\n",
      "Epoch 2/5\n",
      "1288/1288 [==============================] - 0s 326us/step - loss: 0.6861 - acc: 0.5458 - val_loss: 0.6910 - val_acc: 0.5573\n",
      "Epoch 3/5\n",
      "1288/1288 [==============================] - 0s 317us/step - loss: 0.6829 - acc: 0.5404 - val_loss: 0.6908 - val_acc: 0.5604\n",
      "Epoch 4/5\n",
      "1288/1288 [==============================] - 0s 375us/step - loss: 0.6750 - acc: 0.5559 - val_loss: 0.6910 - val_acc: 0.5604\n",
      "Epoch 5/5\n",
      "1288/1288 [==============================] - 0s 322us/step - loss: 0.6675 - acc: 0.6071 - val_loss: 0.6929 - val_acc: 0.5728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s 242us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_521 (Dense)            (None, 16)                10528     \n",
      "_________________________________________________________________\n",
      "dropout_345 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_510 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_522 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_346 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_511 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_523 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_512 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10,817\n",
      "Trainable params: 10,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/5\n",
      "1288/1288 [==============================] - 14s 11ms/step - loss: 0.6944 - acc: 0.4736 - val_loss: 0.6923 - val_acc: 0.5418\n",
      "Epoch 2/5\n",
      "1288/1288 [==============================] - 0s 382us/step - loss: 0.6908 - acc: 0.5714 - val_loss: 0.6911 - val_acc: 0.5511\n",
      "Epoch 3/5\n",
      "1288/1288 [==============================] - 0s 373us/step - loss: 0.6877 - acc: 0.5683 - val_loss: 0.6905 - val_acc: 0.5573\n",
      "Epoch 4/5\n",
      "1288/1288 [==============================] - 0s 348us/step - loss: 0.6824 - acc: 0.5955 - val_loss: 0.6890 - val_acc: 0.5542\n",
      "Epoch 5/5\n",
      "1288/1288 [==============================] - 0s 383us/step - loss: 0.6737 - acc: 0.6335 - val_loss: 0.6880 - val_acc: 0.5635\n",
      "379/379 [==============================] - 0s 308us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_524 (Dense)            (None, 24)                15792     \n",
      "_________________________________________________________________\n",
      "dropout_347 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_513 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_525 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_348 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_514 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_526 (Dense)            (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "activation_515 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 16,417\n",
      "Trainable params: 16,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/5\n",
      "1288/1288 [==============================] - 17s 13ms/step - loss: 0.6926 - acc: 0.5016 - val_loss: 0.6899 - val_acc: 0.5449\n",
      "Epoch 2/5\n",
      "1288/1288 [==============================] - 0s 386us/step - loss: 0.6866 - acc: 0.5419 - val_loss: 0.6869 - val_acc: 0.5511\n",
      "Epoch 3/5\n",
      "1288/1288 [==============================] - 1s 393us/step - loss: 0.6819 - acc: 0.5458 - val_loss: 0.6859 - val_acc: 0.5511\n",
      "Epoch 4/5\n",
      "1288/1288 [==============================] - 0s 335us/step - loss: 0.6697 - acc: 0.6196 - val_loss: 0.6843 - val_acc: 0.5511\n",
      "Epoch 5/5\n",
      "1288/1288 [==============================] - 0s 335us/step - loss: 0.6540 - acc: 0.6390 - val_loss: 0.6862 - val_acc: 0.5480\n",
      "379/379 [==============================] - 0s 258us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_527 (Dense)            (None, 32)                21056     \n",
      "_________________________________________________________________\n",
      "dropout_349 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_516 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_528 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_350 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_517 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_529 (Dense)            (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_518 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 22,145\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/5\n",
      "1288/1288 [==============================] - 16s 13ms/step - loss: 0.6915 - acc: 0.5303 - val_loss: 0.6898 - val_acc: 0.5511\n",
      "Epoch 2/5\n",
      "1288/1288 [==============================] - 1s 455us/step - loss: 0.6865 - acc: 0.5396 - val_loss: 0.6888 - val_acc: 0.5511\n",
      "Epoch 3/5\n",
      "1288/1288 [==============================] - 1s 525us/step - loss: 0.6780 - acc: 0.5427 - val_loss: 0.6873 - val_acc: 0.5480\n",
      "Epoch 4/5\n",
      "1288/1288 [==============================] - 1s 509us/step - loss: 0.6621 - acc: 0.5963 - val_loss: 0.6885 - val_acc: 0.5356\n",
      "Epoch 5/5\n",
      "1288/1288 [==============================] - 1s 495us/step - loss: 0.6294 - acc: 0.6957 - val_loss: 0.7028 - val_acc: 0.5604\n",
      "379/379 [==============================] - 0s 316us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_530 (Dense)            (None, 40)                26320     \n",
      "_________________________________________________________________\n",
      "dropout_351 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_519 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_531 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_352 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_520 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_532 (Dense)            (None, 1)                 41        \n",
      "_________________________________________________________________\n",
      "activation_521 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,001\n",
      "Trainable params: 28,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/5\n",
      "1288/1288 [==============================] - 19s 15ms/step - loss: 0.6931 - acc: 0.5217 - val_loss: 0.6895 - val_acc: 0.5511\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288/1288 [==============================] - 1s 413us/step - loss: 0.6863 - acc: 0.5497 - val_loss: 0.6887 - val_acc: 0.5511\n",
      "Epoch 3/5\n",
      "1288/1288 [==============================] - 1s 484us/step - loss: 0.6780 - acc: 0.5668 - val_loss: 0.6881 - val_acc: 0.5697\n",
      "Epoch 4/5\n",
      "1288/1288 [==============================] - 1s 513us/step - loss: 0.6569 - acc: 0.6498 - val_loss: 0.6874 - val_acc: 0.5511\n",
      "Epoch 5/5\n",
      "1288/1288 [==============================] - 1s 432us/step - loss: 0.6197 - acc: 0.7151 - val_loss: 0.6946 - val_acc: 0.5604\n",
      "379/379 [==============================] - 0s 300us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_533 (Dense)            (None, 48)                31584     \n",
      "_________________________________________________________________\n",
      "dropout_353 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_522 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_534 (Dense)            (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dropout_354 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_523 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_535 (Dense)            (None, 1)                 49        \n",
      "_________________________________________________________________\n",
      "activation_524 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33,985\n",
      "Trainable params: 33,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/5\n",
      "1288/1288 [==============================] - 17s 14ms/step - loss: 0.6924 - acc: 0.5419 - val_loss: 0.6880 - val_acc: 0.5511\n",
      "Epoch 2/5\n",
      "1288/1288 [==============================] - 1s 494us/step - loss: 0.6844 - acc: 0.5388 - val_loss: 0.6859 - val_acc: 0.5511\n",
      "Epoch 3/5\n",
      "1288/1288 [==============================] - 1s 626us/step - loss: 0.6749 - acc: 0.5419 - val_loss: 0.6834 - val_acc: 0.5573\n",
      "Epoch 4/5\n",
      "1288/1288 [==============================] - 1s 434us/step - loss: 0.6523 - acc: 0.5955 - val_loss: 0.6826 - val_acc: 0.5294\n",
      "Epoch 5/5\n",
      "1288/1288 [==============================] - 1s 443us/step - loss: 0.6035 - acc: 0.7197 - val_loss: 0.7002 - val_acc: 0.5325\n",
      "379/379 [==============================] - 0s 266us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_536 (Dense)            (None, 56)                36848     \n",
      "_________________________________________________________________\n",
      "dropout_355 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_525 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_537 (Dense)            (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dropout_356 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_526 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_538 (Dense)            (None, 1)                 57        \n",
      "_________________________________________________________________\n",
      "activation_527 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,097\n",
      "Trainable params: 40,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/5\n",
      "1288/1288 [==============================] - 17s 13ms/step - loss: 0.6919 - acc: 0.5388 - val_loss: 0.6889 - val_acc: 0.5511\n",
      "Epoch 2/5\n",
      "1288/1288 [==============================] - 1s 451us/step - loss: 0.6871 - acc: 0.5396 - val_loss: 0.6873 - val_acc: 0.5511\n",
      "Epoch 3/5\n",
      "1288/1288 [==============================] - 1s 455us/step - loss: 0.6762 - acc: 0.5404 - val_loss: 0.6872 - val_acc: 0.5511\n",
      "Epoch 4/5\n",
      "1288/1288 [==============================] - 1s 448us/step - loss: 0.6576 - acc: 0.5738 - val_loss: 0.6863 - val_acc: 0.5449\n",
      "Epoch 5/5\n",
      "1288/1288 [==============================] - 1s 447us/step - loss: 0.6165 - acc: 0.6708 - val_loss: 0.6917 - val_acc: 0.5356\n",
      "379/379 [==============================] - 0s 287us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_539 (Dense)            (None, 64)                42112     \n",
      "_________________________________________________________________\n",
      "dropout_357 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_528 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_540 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_358 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_529 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_541 (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_530 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 46,337\n",
      "Trainable params: 46,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/5\n",
      "1288/1288 [==============================] - 16s 13ms/step - loss: 0.6920 - acc: 0.5233 - val_loss: 0.6883 - val_acc: 0.5511\n",
      "Epoch 2/5\n",
      "1288/1288 [==============================] - 1s 531us/step - loss: 0.6820 - acc: 0.5411 - val_loss: 0.6887 - val_acc: 0.5511\n",
      "Epoch 3/5\n",
      "1288/1288 [==============================] - 1s 526us/step - loss: 0.6669 - acc: 0.5730 - val_loss: 0.6907 - val_acc: 0.5263\n",
      "Epoch 4/5\n",
      "1288/1288 [==============================] - 1s 509us/step - loss: 0.6279 - acc: 0.7143 - val_loss: 0.7024 - val_acc: 0.4892\n",
      "Epoch 5/5\n",
      "1288/1288 [==============================] - 1s 495us/step - loss: 0.5531 - acc: 0.7787 - val_loss: 0.7364 - val_acc: 0.5201\n",
      "379/379 [==============================] - 0s 271us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_542 (Dense)            (None, 8)                 5264      \n",
      "_________________________________________________________________\n",
      "dropout_359 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_531 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_543 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_360 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_532 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_544 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_533 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,345\n",
      "Trainable params: 5,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/6\n",
      "1288/1288 [==============================] - 17s 13ms/step - loss: 0.6932 - acc: 0.4899 - val_loss: 0.6919 - val_acc: 0.5387\n",
      "Epoch 2/6\n",
      "1288/1288 [==============================] - 0s 337us/step - loss: 0.6902 - acc: 0.5505 - val_loss: 0.6903 - val_acc: 0.5387\n",
      "Epoch 3/6\n",
      "1288/1288 [==============================] - 0s 335us/step - loss: 0.6879 - acc: 0.5644 - val_loss: 0.6894 - val_acc: 0.5449\n",
      "Epoch 4/6\n",
      "1288/1288 [==============================] - 0s 338us/step - loss: 0.6854 - acc: 0.5745 - val_loss: 0.6888 - val_acc: 0.5449\n",
      "Epoch 5/6\n",
      "1288/1288 [==============================] - 0s 331us/step - loss: 0.6812 - acc: 0.5862 - val_loss: 0.6883 - val_acc: 0.5480\n",
      "Epoch 6/6\n",
      "1288/1288 [==============================] - 0s 335us/step - loss: 0.6748 - acc: 0.6017 - val_loss: 0.6876 - val_acc: 0.5542\n",
      "379/379 [==============================] - 0s 295us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_545 (Dense)            (None, 16)                10528     \n",
      "_________________________________________________________________\n",
      "dropout_361 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_534 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_546 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_362 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_535 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_547 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_536 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10,817\n",
      "Trainable params: 10,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/6\n",
      "1288/1288 [==============================] - 17s 13ms/step - loss: 0.6923 - acc: 0.5342 - val_loss: 0.6909 - val_acc: 0.5480\n",
      "Epoch 2/6\n",
      "1288/1288 [==============================] - 1s 542us/step - loss: 0.6885 - acc: 0.5388 - val_loss: 0.6896 - val_acc: 0.5511\n",
      "Epoch 3/6\n",
      "1288/1288 [==============================] - 0s 343us/step - loss: 0.6854 - acc: 0.5411 - val_loss: 0.6890 - val_acc: 0.5511\n",
      "Epoch 4/6\n",
      "1288/1288 [==============================] - 0s 336us/step - loss: 0.6815 - acc: 0.5753 - val_loss: 0.6892 - val_acc: 0.5449\n",
      "Epoch 5/6\n",
      "1288/1288 [==============================] - 0s 369us/step - loss: 0.6700 - acc: 0.5963 - val_loss: 0.6889 - val_acc: 0.5294\n",
      "Epoch 6/6\n",
      "1288/1288 [==============================] - 1s 394us/step - loss: 0.6590 - acc: 0.6351 - val_loss: 0.6889 - val_acc: 0.5356\n",
      "379/379 [==============================] - 0s 339us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_548 (Dense)            (None, 24)                15792     \n",
      "_________________________________________________________________\n",
      "dropout_363 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_537 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_549 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_364 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_538 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_550 (Dense)            (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "activation_539 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 16,417\n",
      "Trainable params: 16,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/6\n",
      "1288/1288 [==============================] - 17s 13ms/step - loss: 0.6916 - acc: 0.5311 - val_loss: 0.6903 - val_acc: 0.5511\n",
      "Epoch 2/6\n",
      "1288/1288 [==============================] - 1s 393us/step - loss: 0.6855 - acc: 0.5396 - val_loss: 0.6879 - val_acc: 0.5511\n",
      "Epoch 3/6\n",
      "1288/1288 [==============================] - 0s 384us/step - loss: 0.6792 - acc: 0.5435 - val_loss: 0.6870 - val_acc: 0.5511\n",
      "Epoch 4/6\n",
      "1288/1288 [==============================] - 1s 400us/step - loss: 0.6670 - acc: 0.5730 - val_loss: 0.6857 - val_acc: 0.5480\n",
      "Epoch 5/6\n",
      "1288/1288 [==============================] - 1s 448us/step - loss: 0.6409 - acc: 0.6444 - val_loss: 0.6853 - val_acc: 0.5418\n",
      "Epoch 6/6\n",
      "1288/1288 [==============================] - 0s 351us/step - loss: 0.5968 - acc: 0.7430 - val_loss: 0.6979 - val_acc: 0.5697\n",
      "379/379 [==============================] - 0s 216us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_551 (Dense)            (None, 32)                21056     \n",
      "_________________________________________________________________\n",
      "dropout_365 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_540 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_552 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_366 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_541 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_553 (Dense)            (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_542 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 22,145\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/6\n",
      "1288/1288 [==============================] - 18s 14ms/step - loss: 0.6925 - acc: 0.5124 - val_loss: 0.6891 - val_acc: 0.5480\n",
      "Epoch 2/6\n",
      "1288/1288 [==============================] - 1s 533us/step - loss: 0.6853 - acc: 0.5411 - val_loss: 0.6877 - val_acc: 0.5511\n",
      "Epoch 3/6\n",
      "1288/1288 [==============================] - 1s 435us/step - loss: 0.6796 - acc: 0.5497 - val_loss: 0.6874 - val_acc: 0.5480\n",
      "Epoch 4/6\n",
      "1288/1288 [==============================] - 0s 383us/step - loss: 0.6670 - acc: 0.5986 - val_loss: 0.6867 - val_acc: 0.5511\n",
      "Epoch 5/6\n",
      "1288/1288 [==============================] - 1s 401us/step - loss: 0.6446 - acc: 0.6545 - val_loss: 0.6893 - val_acc: 0.5573\n",
      "Epoch 6/6\n",
      "1288/1288 [==============================] - 1s 470us/step - loss: 0.5951 - acc: 0.7352 - val_loss: 0.7006 - val_acc: 0.5232\n",
      "379/379 [==============================] - 0s 221us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_554 (Dense)            (None, 40)                26320     \n",
      "_________________________________________________________________\n",
      "dropout_367 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_543 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_555 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_368 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_544 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_556 (Dense)            (None, 1)                 41        \n",
      "_________________________________________________________________\n",
      "activation_545 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,001\n",
      "Trainable params: 28,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/6\n",
      "1288/1288 [==============================] - 18s 14ms/step - loss: 0.6916 - acc: 0.5241 - val_loss: 0.6895 - val_acc: 0.5480\n",
      "Epoch 2/6\n",
      "1288/1288 [==============================] - 1s 399us/step - loss: 0.6843 - acc: 0.5489 - val_loss: 0.6887 - val_acc: 0.5511\n",
      "Epoch 3/6\n",
      "1288/1288 [==============================] - 1s 430us/step - loss: 0.6761 - acc: 0.5551 - val_loss: 0.6871 - val_acc: 0.5542\n",
      "Epoch 4/6\n",
      "1288/1288 [==============================] - 1s 406us/step - loss: 0.6530 - acc: 0.6460 - val_loss: 0.6855 - val_acc: 0.5294\n",
      "Epoch 5/6\n",
      "1288/1288 [==============================] - 1s 420us/step - loss: 0.6062 - acc: 0.7500 - val_loss: 0.6942 - val_acc: 0.5356\n",
      "Epoch 6/6\n",
      "1288/1288 [==============================] - 1s 542us/step - loss: 0.5352 - acc: 0.7795 - val_loss: 0.7185 - val_acc: 0.5356\n",
      "379/379 [==============================] - 0s 326us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_557 (Dense)            (None, 48)                31584     \n",
      "_________________________________________________________________\n",
      "dropout_369 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_546 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_558 (Dense)            (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dropout_370 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_547 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_559 (Dense)            (None, 1)                 49        \n",
      "_________________________________________________________________\n",
      "activation_548 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33,985\n",
      "Trainable params: 33,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/6\n",
      "1288/1288 [==============================] - 20s 15ms/step - loss: 0.6925 - acc: 0.5101 - val_loss: 0.6893 - val_acc: 0.5511\n",
      "Epoch 2/6\n",
      "1288/1288 [==============================] - 1s 616us/step - loss: 0.6848 - acc: 0.5512 - val_loss: 0.6875 - val_acc: 0.5449\n",
      "Epoch 3/6\n",
      "1288/1288 [==============================] - 1s 505us/step - loss: 0.6739 - acc: 0.5675 - val_loss: 0.6871 - val_acc: 0.5666\n",
      "Epoch 4/6\n",
      "1288/1288 [==============================] - 1s 451us/step - loss: 0.6446 - acc: 0.7104 - val_loss: 0.6898 - val_acc: 0.5728\n",
      "Epoch 5/6\n",
      "1288/1288 [==============================] - 1s 470us/step - loss: 0.5896 - acc: 0.7376 - val_loss: 0.7036 - val_acc: 0.5418\n",
      "Epoch 6/6\n",
      "1288/1288 [==============================] - 1s 466us/step - loss: 0.5045 - acc: 0.8059 - val_loss: 0.7531 - val_acc: 0.5232\n",
      "379/379 [==============================] - 0s 274us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_560 (Dense)            (None, 56)                36848     \n",
      "_________________________________________________________________\n",
      "dropout_371 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_549 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_561 (Dense)            (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dropout_372 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_550 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_562 (Dense)            (None, 1)                 57        \n",
      "_________________________________________________________________\n",
      "activation_551 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,097\n",
      "Trainable params: 40,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/6\n",
      "1288/1288 [==============================] - 18s 14ms/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6887 - val_acc: 0.5511\n",
      "Epoch 2/6\n",
      "1288/1288 [==============================] - 1s 500us/step - loss: 0.6867 - acc: 0.5435 - val_loss: 0.6877 - val_acc: 0.5511\n",
      "Epoch 3/6\n",
      "1288/1288 [==============================] - 1s 614us/step - loss: 0.6761 - acc: 0.5862 - val_loss: 0.6853 - val_acc: 0.5511\n",
      "Epoch 4/6\n",
      "1288/1288 [==============================] - 1s 516us/step - loss: 0.6499 - acc: 0.6964 - val_loss: 0.6876 - val_acc: 0.5294\n",
      "Epoch 5/6\n",
      "1288/1288 [==============================] - 1s 495us/step - loss: 0.5844 - acc: 0.7679 - val_loss: 0.7069 - val_acc: 0.5387\n",
      "Epoch 6/6\n",
      "1288/1288 [==============================] - 1s 548us/step - loss: 0.4894 - acc: 0.8152 - val_loss: 0.7671 - val_acc: 0.5139\n",
      "379/379 [==============================] - 0s 274us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_563 (Dense)            (None, 64)                42112     \n",
      "_________________________________________________________________\n",
      "dropout_373 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_552 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_564 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_374 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_553 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_565 (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_554 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 46,337\n",
      "Trainable params: 46,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/6\n",
      "1288/1288 [==============================] - 17s 13ms/step - loss: 0.6931 - acc: 0.5233 - val_loss: 0.6891 - val_acc: 0.5511\n",
      "Epoch 2/6\n",
      "1288/1288 [==============================] - 1s 506us/step - loss: 0.6854 - acc: 0.5396 - val_loss: 0.6879 - val_acc: 0.5511\n",
      "Epoch 3/6\n",
      "1288/1288 [==============================] - 1s 538us/step - loss: 0.6725 - acc: 0.6025 - val_loss: 0.6866 - val_acc: 0.5511\n",
      "Epoch 4/6\n",
      "1288/1288 [==============================] - 1s 516us/step - loss: 0.6349 - acc: 0.6483 - val_loss: 0.6903 - val_acc: 0.5201\n",
      "Epoch 5/6\n",
      "1288/1288 [==============================] - 1s 495us/step - loss: 0.5617 - acc: 0.7578 - val_loss: 0.7243 - val_acc: 0.5449\n",
      "Epoch 6/6\n",
      "1288/1288 [==============================] - 1s 529us/step - loss: 0.4492 - acc: 0.8385 - val_loss: 0.7950 - val_acc: 0.5263\n",
      "379/379 [==============================] - 0s 276us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_566 (Dense)            (None, 8)                 5264      \n",
      "_________________________________________________________________\n",
      "dropout_375 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_555 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_567 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_376 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_556 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_568 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_557 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,345\n",
      "Trainable params: 5,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/7\n",
      "1288/1288 [==============================] - 17s 13ms/step - loss: 0.6921 - acc: 0.5419 - val_loss: 0.6883 - val_acc: 0.5511\n",
      "Epoch 2/7\n",
      "1288/1288 [==============================] - 1s 390us/step - loss: 0.6883 - acc: 0.5411 - val_loss: 0.6874 - val_acc: 0.5511\n",
      "Epoch 3/7\n",
      "1288/1288 [==============================] - 0s 362us/step - loss: 0.6841 - acc: 0.5474 - val_loss: 0.6866 - val_acc: 0.5511\n",
      "Epoch 4/7\n",
      "1288/1288 [==============================] - 0s 356us/step - loss: 0.6781 - acc: 0.5722 - val_loss: 0.6859 - val_acc: 0.5480\n",
      "Epoch 5/7\n",
      "1288/1288 [==============================] - 0s 372us/step - loss: 0.6691 - acc: 0.5916 - val_loss: 0.6857 - val_acc: 0.5418\n",
      "Epoch 6/7\n",
      "1288/1288 [==============================] - 0s 365us/step - loss: 0.6585 - acc: 0.6196 - val_loss: 0.6859 - val_acc: 0.5542\n",
      "Epoch 7/7\n",
      "1288/1288 [==============================] - 0s 365us/step - loss: 0.6400 - acc: 0.6724 - val_loss: 0.6869 - val_acc: 0.5511\n",
      "379/379 [==============================] - 0s 297us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_569 (Dense)            (None, 16)                10528     \n",
      "_________________________________________________________________\n",
      "dropout_377 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_558 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_570 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_378 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_559 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_571 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_560 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10,817\n",
      "Trainable params: 10,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/7\n",
      "1288/1288 [==============================] - 17s 13ms/step - loss: 0.6924 - acc: 0.4969 - val_loss: 0.6905 - val_acc: 0.5449\n",
      "Epoch 2/7\n",
      "1288/1288 [==============================] - 0s 348us/step - loss: 0.6854 - acc: 0.5543 - val_loss: 0.6888 - val_acc: 0.5542\n",
      "Epoch 3/7\n",
      "1288/1288 [==============================] - 0s 359us/step - loss: 0.6797 - acc: 0.5598 - val_loss: 0.6878 - val_acc: 0.5542\n",
      "Epoch 4/7\n",
      "1288/1288 [==============================] - 0s 370us/step - loss: 0.6699 - acc: 0.5870 - val_loss: 0.6868 - val_acc: 0.5542\n",
      "Epoch 5/7\n",
      "1288/1288 [==============================] - 0s 345us/step - loss: 0.6525 - acc: 0.6398 - val_loss: 0.6872 - val_acc: 0.5232\n",
      "Epoch 6/7\n",
      "1288/1288 [==============================] - 0s 348us/step - loss: 0.6263 - acc: 0.7112 - val_loss: 0.6958 - val_acc: 0.5511\n",
      "Epoch 7/7\n",
      "1288/1288 [==============================] - 0s 350us/step - loss: 0.5943 - acc: 0.7321 - val_loss: 0.7030 - val_acc: 0.5387\n",
      "379/379 [==============================] - 0s 263us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_572 (Dense)            (None, 24)                15792     \n",
      "_________________________________________________________________\n",
      "dropout_379 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_561 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_573 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_380 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_562 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_574 (Dense)            (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "activation_563 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 16,417\n",
      "Trainable params: 16,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/7\n",
      "1288/1288 [==============================] - 16s 13ms/step - loss: 0.6924 - acc: 0.5287 - val_loss: 0.6911 - val_acc: 0.5480\n",
      "Epoch 2/7\n",
      "1288/1288 [==============================] - 0s 360us/step - loss: 0.6854 - acc: 0.5458 - val_loss: 0.6904 - val_acc: 0.5511\n",
      "Epoch 3/7\n",
      "1288/1288 [==============================] - 0s 369us/step - loss: 0.6781 - acc: 0.5807 - val_loss: 0.6900 - val_acc: 0.5573\n",
      "Epoch 4/7\n",
      "1288/1288 [==============================] - 1s 643us/step - loss: 0.6628 - acc: 0.6405 - val_loss: 0.6909 - val_acc: 0.5604\n",
      "Epoch 5/7\n",
      "1288/1288 [==============================] - 1s 630us/step - loss: 0.6379 - acc: 0.6762 - val_loss: 0.6946 - val_acc: 0.5418\n",
      "Epoch 6/7\n",
      "1288/1288 [==============================] - 1s 599us/step - loss: 0.5920 - acc: 0.7345 - val_loss: 0.7057 - val_acc: 0.5108\n",
      "Epoch 7/7\n",
      "1288/1288 [==============================] - 0s 370us/step - loss: 0.5335 - acc: 0.7787 - val_loss: 0.7278 - val_acc: 0.5263\n",
      "379/379 [==============================] - 0s 300us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_575 (Dense)            (None, 32)                21056     \n",
      "_________________________________________________________________\n",
      "dropout_381 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_564 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_576 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_382 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_565 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_577 (Dense)            (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_566 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 22,145\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/7\n",
      "1288/1288 [==============================] - 21s 17ms/step - loss: 0.6913 - acc: 0.5365 - val_loss: 0.6898 - val_acc: 0.5511\n",
      "Epoch 2/7\n",
      "1288/1288 [==============================] - 1s 461us/step - loss: 0.6846 - acc: 0.5489 - val_loss: 0.6888 - val_acc: 0.5511\n",
      "Epoch 3/7\n",
      "1288/1288 [==============================] - 1s 743us/step - loss: 0.6742 - acc: 0.5590 - val_loss: 0.6883 - val_acc: 0.5356\n",
      "Epoch 4/7\n",
      "1288/1288 [==============================] - 1s 863us/step - loss: 0.6578 - acc: 0.6444 - val_loss: 0.6908 - val_acc: 0.5480\n",
      "Epoch 5/7\n",
      "1288/1288 [==============================] - 1s 641us/step - loss: 0.6279 - acc: 0.6941 - val_loss: 0.7006 - val_acc: 0.5511\n",
      "Epoch 6/7\n",
      "1288/1288 [==============================] - 1s 577us/step - loss: 0.5713 - acc: 0.7554 - val_loss: 0.7155 - val_acc: 0.5294\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288/1288 [==============================] - 1s 558us/step - loss: 0.5032 - acc: 0.8059 - val_loss: 0.7477 - val_acc: 0.5294\n",
      "379/379 [==============================] - 0s 305us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_578 (Dense)            (None, 40)                26320     \n",
      "_________________________________________________________________\n",
      "dropout_383 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_567 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_579 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_384 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_568 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_580 (Dense)            (None, 1)                 41        \n",
      "_________________________________________________________________\n",
      "activation_569 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,001\n",
      "Trainable params: 28,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/7\n",
      "1288/1288 [==============================] - 19s 15ms/step - loss: 0.6923 - acc: 0.5225 - val_loss: 0.6889 - val_acc: 0.5511\n",
      "Epoch 2/7\n",
      "1288/1288 [==============================] - 1s 607us/step - loss: 0.6847 - acc: 0.5505 - val_loss: 0.6880 - val_acc: 0.5511\n",
      "Epoch 3/7\n",
      "1288/1288 [==============================] - 1s 507us/step - loss: 0.6741 - acc: 0.5613 - val_loss: 0.6861 - val_acc: 0.5728\n",
      "Epoch 4/7\n",
      "1288/1288 [==============================] - 1s 606us/step - loss: 0.6525 - acc: 0.6514 - val_loss: 0.6866 - val_acc: 0.5511\n",
      "Epoch 5/7\n",
      "1288/1288 [==============================] - 1s 531us/step - loss: 0.6067 - acc: 0.7306 - val_loss: 0.6976 - val_acc: 0.5697\n",
      "Epoch 6/7\n",
      "1288/1288 [==============================] - 1s 536us/step - loss: 0.5358 - acc: 0.7896 - val_loss: 0.7320 - val_acc: 0.5542\n",
      "Epoch 7/7\n",
      "1288/1288 [==============================] - 1s 569us/step - loss: 0.4547 - acc: 0.8307 - val_loss: 0.7821 - val_acc: 0.5387\n",
      "379/379 [==============================] - 0s 313us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_581 (Dense)            (None, 48)                31584     \n",
      "_________________________________________________________________\n",
      "dropout_385 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_570 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_582 (Dense)            (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dropout_386 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_571 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_583 (Dense)            (None, 1)                 49        \n",
      "_________________________________________________________________\n",
      "activation_572 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33,985\n",
      "Trainable params: 33,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/7\n",
      "1288/1288 [==============================] - 21s 16ms/step - loss: 0.6915 - acc: 0.5326 - val_loss: 0.6868 - val_acc: 0.5511\n",
      "Epoch 2/7\n",
      "1288/1288 [==============================] - 1s 527us/step - loss: 0.6839 - acc: 0.5450 - val_loss: 0.6858 - val_acc: 0.5511\n",
      "Epoch 3/7\n",
      "1288/1288 [==============================] - 1s 441us/step - loss: 0.6717 - acc: 0.5613 - val_loss: 0.6844 - val_acc: 0.5604\n",
      "Epoch 4/7\n",
      "1288/1288 [==============================] - 1s 550us/step - loss: 0.6425 - acc: 0.6669 - val_loss: 0.6906 - val_acc: 0.5046\n",
      "Epoch 5/7\n",
      "1288/1288 [==============================] - 1s 541us/step - loss: 0.5859 - acc: 0.7484 - val_loss: 0.7053 - val_acc: 0.5480\n",
      "Epoch 6/7\n",
      "1288/1288 [==============================] - 1s 465us/step - loss: 0.5058 - acc: 0.8020 - val_loss: 0.7393 - val_acc: 0.5263\n",
      "Epoch 7/7\n",
      "1288/1288 [==============================] - 1s 570us/step - loss: 0.4078 - acc: 0.8571 - val_loss: 0.8178 - val_acc: 0.5325\n",
      "379/379 [==============================] - 0s 305us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_584 (Dense)            (None, 56)                36848     \n",
      "_________________________________________________________________\n",
      "dropout_387 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_573 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_585 (Dense)            (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dropout_388 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_574 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_586 (Dense)            (None, 1)                 57        \n",
      "_________________________________________________________________\n",
      "activation_575 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,097\n",
      "Trainable params: 40,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/7\n",
      "1288/1288 [==============================] - 19s 15ms/step - loss: 0.6907 - acc: 0.5427 - val_loss: 0.6883 - val_acc: 0.5511\n",
      "Epoch 2/7\n",
      "1288/1288 [==============================] - 1s 455us/step - loss: 0.6825 - acc: 0.5505 - val_loss: 0.6875 - val_acc: 0.5511\n",
      "Epoch 3/7\n",
      "1288/1288 [==============================] - 1s 475us/step - loss: 0.6672 - acc: 0.5761 - val_loss: 0.6886 - val_acc: 0.5480\n",
      "Epoch 4/7\n",
      "1288/1288 [==============================] - 1s 475us/step - loss: 0.6287 - acc: 0.6972 - val_loss: 0.6922 - val_acc: 0.5387\n",
      "Epoch 5/7\n",
      "1288/1288 [==============================] - 1s 639us/step - loss: 0.5622 - acc: 0.7484 - val_loss: 0.7241 - val_acc: 0.5046\n",
      "Epoch 6/7\n",
      "1288/1288 [==============================] - 1s 515us/step - loss: 0.4818 - acc: 0.7974 - val_loss: 0.7685 - val_acc: 0.4954\n",
      "Epoch 7/7\n",
      "1288/1288 [==============================] - 1s 459us/step - loss: 0.3973 - acc: 0.8494 - val_loss: 0.8460 - val_acc: 0.5046\n",
      "379/379 [==============================] - 0s 276us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_587 (Dense)            (None, 64)                42112     \n",
      "_________________________________________________________________\n",
      "dropout_389 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_576 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_588 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_390 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_577 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_589 (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_578 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 46,337\n",
      "Trainable params: 46,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/7\n",
      "1288/1288 [==============================] - 17s 14ms/step - loss: 0.6914 - acc: 0.5427 - val_loss: 0.6886 - val_acc: 0.5511\n",
      "Epoch 2/7\n",
      "1288/1288 [==============================] - 1s 517us/step - loss: 0.6832 - acc: 0.5411 - val_loss: 0.6872 - val_acc: 0.5511\n",
      "Epoch 3/7\n",
      "1288/1288 [==============================] - 1s 493us/step - loss: 0.6689 - acc: 0.5877 - val_loss: 0.6867 - val_acc: 0.5573\n",
      "Epoch 4/7\n",
      "1288/1288 [==============================] - 1s 495us/step - loss: 0.6265 - acc: 0.6941 - val_loss: 0.6909 - val_acc: 0.5108\n",
      "Epoch 5/7\n",
      "1288/1288 [==============================] - 1s 501us/step - loss: 0.5550 - acc: 0.7710 - val_loss: 0.7248 - val_acc: 0.5232\n",
      "Epoch 6/7\n",
      "1288/1288 [==============================] - 1s 492us/step - loss: 0.4504 - acc: 0.8385 - val_loss: 0.7892 - val_acc: 0.5263\n",
      "Epoch 7/7\n",
      "1288/1288 [==============================] - 1s 495us/step - loss: 0.3367 - acc: 0.8967 - val_loss: 0.8842 - val_acc: 0.5294\n",
      "379/379 [==============================] - 0s 266us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_590 (Dense)            (None, 8)                 5264      \n",
      "_________________________________________________________________\n",
      "dropout_391 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_579 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_591 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_392 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_580 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_592 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_581 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,345\n",
      "Trainable params: 5,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/8\n",
      "1288/1288 [==============================] - 17s 13ms/step - loss: 0.6931 - acc: 0.5217 - val_loss: 0.6919 - val_acc: 0.5449\n",
      "Epoch 2/8\n",
      "1288/1288 [==============================] - 0s 356us/step - loss: 0.6899 - acc: 0.5489 - val_loss: 0.6909 - val_acc: 0.5511\n",
      "Epoch 3/8\n",
      "1288/1288 [==============================] - 0s 355us/step - loss: 0.6869 - acc: 0.5466 - val_loss: 0.6910 - val_acc: 0.5387\n",
      "Epoch 4/8\n",
      "1288/1288 [==============================] - 0s 355us/step - loss: 0.6824 - acc: 0.5660 - val_loss: 0.6906 - val_acc: 0.5418\n",
      "Epoch 5/8\n",
      "1288/1288 [==============================] - 0s 351us/step - loss: 0.6780 - acc: 0.5807 - val_loss: 0.6912 - val_acc: 0.5449\n",
      "Epoch 6/8\n",
      "1288/1288 [==============================] - 0s 357us/step - loss: 0.6707 - acc: 0.6064 - val_loss: 0.6919 - val_acc: 0.5449\n",
      "Epoch 7/8\n",
      "1288/1288 [==============================] - 0s 362us/step - loss: 0.6615 - acc: 0.6219 - val_loss: 0.6939 - val_acc: 0.5325\n",
      "Epoch 8/8\n",
      "1288/1288 [==============================] - 0s 359us/step - loss: 0.6474 - acc: 0.6436 - val_loss: 0.6954 - val_acc: 0.5294\n",
      "379/379 [==============================] - 0s 271us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_593 (Dense)            (None, 16)                10528     \n",
      "_________________________________________________________________\n",
      "dropout_393 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_582 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_594 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_394 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_583 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_595 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_584 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10,817\n",
      "Trainable params: 10,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/8\n",
      "1288/1288 [==============================] - 18s 14ms/step - loss: 0.6913 - acc: 0.5248 - val_loss: 0.6893 - val_acc: 0.5511\n",
      "Epoch 2/8\n",
      "1288/1288 [==============================] - 0s 355us/step - loss: 0.6857 - acc: 0.5388 - val_loss: 0.6884 - val_acc: 0.5511\n",
      "Epoch 3/8\n",
      "1288/1288 [==============================] - 0s 354us/step - loss: 0.6779 - acc: 0.5512 - val_loss: 0.6881 - val_acc: 0.5480\n",
      "Epoch 4/8\n",
      "1288/1288 [==============================] - 0s 354us/step - loss: 0.6691 - acc: 0.5683 - val_loss: 0.6882 - val_acc: 0.5449\n",
      "Epoch 5/8\n",
      "1288/1288 [==============================] - 0s 352us/step - loss: 0.6531 - acc: 0.5994 - val_loss: 0.6890 - val_acc: 0.5511\n",
      "Epoch 6/8\n",
      "1288/1288 [==============================] - 0s 352us/step - loss: 0.6307 - acc: 0.6615 - val_loss: 0.6895 - val_acc: 0.5542\n",
      "Epoch 7/8\n",
      "1288/1288 [==============================] - 0s 371us/step - loss: 0.5980 - acc: 0.7267 - val_loss: 0.6955 - val_acc: 0.5542\n",
      "Epoch 8/8\n",
      "1288/1288 [==============================] - 0s 356us/step - loss: 0.5634 - acc: 0.7663 - val_loss: 0.7136 - val_acc: 0.5573\n",
      "379/379 [==============================] - 0s 271us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_596 (Dense)            (None, 24)                15792     \n",
      "_________________________________________________________________\n",
      "dropout_395 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_585 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_597 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_396 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_586 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_598 (Dense)            (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "activation_587 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 16,417\n",
      "Trainable params: 16,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/8\n",
      "1288/1288 [==============================] - 18s 14ms/step - loss: 0.6903 - acc: 0.5388 - val_loss: 0.6881 - val_acc: 0.5511\n",
      "Epoch 2/8\n",
      "1288/1288 [==============================] - 1s 396us/step - loss: 0.6826 - acc: 0.5458 - val_loss: 0.6863 - val_acc: 0.5542\n",
      "Epoch 3/8\n",
      "1288/1288 [==============================] - 0s 374us/step - loss: 0.6702 - acc: 0.5932 - val_loss: 0.6856 - val_acc: 0.5480\n",
      "Epoch 4/8\n",
      "1288/1288 [==============================] - 0s 371us/step - loss: 0.6538 - acc: 0.6157 - val_loss: 0.6858 - val_acc: 0.5387\n",
      "Epoch 5/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288/1288 [==============================] - 0s 387us/step - loss: 0.6228 - acc: 0.7057 - val_loss: 0.6890 - val_acc: 0.5201\n",
      "Epoch 6/8\n",
      "1288/1288 [==============================] - 0s 376us/step - loss: 0.5836 - acc: 0.7446 - val_loss: 0.6972 - val_acc: 0.5015\n",
      "Epoch 7/8\n",
      "1288/1288 [==============================] - 0s 359us/step - loss: 0.5335 - acc: 0.7880 - val_loss: 0.7234 - val_acc: 0.5077\n",
      "Epoch 8/8\n",
      "1288/1288 [==============================] - 0s 359us/step - loss: 0.4801 - acc: 0.8098 - val_loss: 0.7520 - val_acc: 0.5046\n",
      "379/379 [==============================] - 0s 271us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_599 (Dense)            (None, 32)                21056     \n",
      "_________________________________________________________________\n",
      "dropout_397 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_588 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_600 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_398 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_589 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_601 (Dense)            (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_590 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 22,145\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/8\n",
      "1288/1288 [==============================] - 18s 14ms/step - loss: 0.6921 - acc: 0.5318 - val_loss: 0.6874 - val_acc: 0.5511\n",
      "Epoch 2/8\n",
      "1288/1288 [==============================] - 1s 454us/step - loss: 0.6844 - acc: 0.5481 - val_loss: 0.6864 - val_acc: 0.5480\n",
      "Epoch 3/8\n",
      "1288/1288 [==============================] - 1s 451us/step - loss: 0.6724 - acc: 0.5660 - val_loss: 0.6851 - val_acc: 0.5635\n",
      "Epoch 4/8\n",
      "1288/1288 [==============================] - 1s 450us/step - loss: 0.6486 - acc: 0.6599 - val_loss: 0.6870 - val_acc: 0.5573\n",
      "Epoch 5/8\n",
      "1288/1288 [==============================] - 1s 451us/step - loss: 0.6093 - acc: 0.7127 - val_loss: 0.6964 - val_acc: 0.5604\n",
      "Epoch 6/8\n",
      "1288/1288 [==============================] - 1s 452us/step - loss: 0.5470 - acc: 0.7554 - val_loss: 0.7165 - val_acc: 0.5542\n",
      "Epoch 7/8\n",
      "1288/1288 [==============================] - 1s 451us/step - loss: 0.4805 - acc: 0.8067 - val_loss: 0.7524 - val_acc: 0.5511\n",
      "Epoch 8/8\n",
      "1288/1288 [==============================] - 1s 451us/step - loss: 0.4190 - acc: 0.8439 - val_loss: 0.8093 - val_acc: 0.5418\n",
      "379/379 [==============================] - 0s 279us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_602 (Dense)            (None, 40)                26320     \n",
      "_________________________________________________________________\n",
      "dropout_399 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_591 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_603 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_400 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_592 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_604 (Dense)            (None, 1)                 41        \n",
      "_________________________________________________________________\n",
      "activation_593 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,001\n",
      "Trainable params: 28,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/8\n",
      "1288/1288 [==============================] - 18s 14ms/step - loss: 0.6928 - acc: 0.5241 - val_loss: 0.6879 - val_acc: 0.5511\n",
      "Epoch 2/8\n",
      "1288/1288 [==============================] - 1s 453us/step - loss: 0.6840 - acc: 0.5489 - val_loss: 0.6853 - val_acc: 0.5511\n",
      "Epoch 3/8\n",
      "1288/1288 [==============================] - 1s 444us/step - loss: 0.6709 - acc: 0.5652 - val_loss: 0.6823 - val_acc: 0.5542\n",
      "Epoch 4/8\n",
      "1288/1288 [==============================] - 1s 451us/step - loss: 0.6406 - acc: 0.6786 - val_loss: 0.6776 - val_acc: 0.5418\n",
      "Epoch 5/8\n",
      "1288/1288 [==============================] - 1s 450us/step - loss: 0.5821 - acc: 0.7368 - val_loss: 0.6890 - val_acc: 0.5511\n",
      "Epoch 6/8\n",
      "1288/1288 [==============================] - 1s 450us/step - loss: 0.5025 - acc: 0.8067 - val_loss: 0.7207 - val_acc: 0.5449\n",
      "Epoch 7/8\n",
      "1288/1288 [==============================] - 1s 449us/step - loss: 0.4277 - acc: 0.8362 - val_loss: 0.7931 - val_acc: 0.5294\n",
      "Epoch 8/8\n",
      "1288/1288 [==============================] - 1s 449us/step - loss: 0.3387 - acc: 0.8898 - val_loss: 0.8752 - val_acc: 0.5077\n",
      "379/379 [==============================] - 0s 271us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_605 (Dense)            (None, 48)                31584     \n",
      "_________________________________________________________________\n",
      "dropout_401 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_594 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_606 (Dense)            (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dropout_402 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_595 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_607 (Dense)            (None, 1)                 49        \n",
      "_________________________________________________________________\n",
      "activation_596 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33,985\n",
      "Trainable params: 33,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/8\n",
      "1288/1288 [==============================] - 18s 14ms/step - loss: 0.6920 - acc: 0.5334 - val_loss: 0.6879 - val_acc: 0.5511\n",
      "Epoch 2/8\n",
      "1288/1288 [==============================] - 1s 485us/step - loss: 0.6823 - acc: 0.5443 - val_loss: 0.6864 - val_acc: 0.5511\n",
      "Epoch 3/8\n",
      "1288/1288 [==============================] - 1s 448us/step - loss: 0.6702 - acc: 0.5978 - val_loss: 0.6841 - val_acc: 0.5573\n",
      "Epoch 4/8\n",
      "1288/1288 [==============================] - 1s 462us/step - loss: 0.6386 - acc: 0.6825 - val_loss: 0.6862 - val_acc: 0.5635\n",
      "Epoch 5/8\n",
      "1288/1288 [==============================] - 1s 482us/step - loss: 0.5820 - acc: 0.7516 - val_loss: 0.7013 - val_acc: 0.5387\n",
      "Epoch 6/8\n",
      "1288/1288 [==============================] - 1s 439us/step - loss: 0.5032 - acc: 0.7857 - val_loss: 0.7445 - val_acc: 0.5201\n",
      "Epoch 7/8\n",
      "1288/1288 [==============================] - 1s 451us/step - loss: 0.4143 - acc: 0.8439 - val_loss: 0.8184 - val_acc: 0.5232\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288/1288 [==============================] - 1s 451us/step - loss: 0.3357 - acc: 0.8882 - val_loss: 0.8957 - val_acc: 0.5077\n",
      "379/379 [==============================] - 0s 266us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_608 (Dense)            (None, 56)                36848     \n",
      "_________________________________________________________________\n",
      "dropout_403 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_597 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_609 (Dense)            (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dropout_404 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_598 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_610 (Dense)            (None, 1)                 57        \n",
      "_________________________________________________________________\n",
      "activation_599 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,097\n",
      "Trainable params: 40,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/8\n",
      "1288/1288 [==============================] - 19s 14ms/step - loss: 0.6913 - acc: 0.5365 - val_loss: 0.6889 - val_acc: 0.5511\n",
      "Epoch 2/8\n",
      "1288/1288 [==============================] - 1s 486us/step - loss: 0.6828 - acc: 0.5388 - val_loss: 0.6859 - val_acc: 0.5511\n",
      "Epoch 3/8\n",
      "1288/1288 [==============================] - 1s 524us/step - loss: 0.6681 - acc: 0.5776 - val_loss: 0.6852 - val_acc: 0.5542\n",
      "Epoch 4/8\n",
      "1288/1288 [==============================] - 1s 481us/step - loss: 0.6330 - acc: 0.6568 - val_loss: 0.6880 - val_acc: 0.5604\n",
      "Epoch 5/8\n",
      "1288/1288 [==============================] - 1s 505us/step - loss: 0.5547 - acc: 0.7725 - val_loss: 0.7191 - val_acc: 0.5263\n",
      "Epoch 6/8\n",
      "1288/1288 [==============================] - 1s 508us/step - loss: 0.4564 - acc: 0.8253 - val_loss: 0.7964 - val_acc: 0.5294\n",
      "Epoch 7/8\n",
      "1288/1288 [==============================] - 1s 500us/step - loss: 0.3645 - acc: 0.8703 - val_loss: 0.9114 - val_acc: 0.5170\n",
      "Epoch 8/8\n",
      "1288/1288 [==============================] - 1s 492us/step - loss: 0.2830 - acc: 0.9068 - val_loss: 1.0220 - val_acc: 0.5015\n",
      "379/379 [==============================] - 0s 297us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_611 (Dense)            (None, 64)                42112     \n",
      "_________________________________________________________________\n",
      "dropout_405 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_600 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_612 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_406 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_601 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_613 (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_602 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 46,337\n",
      "Trainable params: 46,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/8\n",
      "1288/1288 [==============================] - 19s 15ms/step - loss: 0.6898 - acc: 0.5427 - val_loss: 0.6882 - val_acc: 0.5511\n",
      "Epoch 2/8\n",
      "1288/1288 [==============================] - 1s 575us/step - loss: 0.6795 - acc: 0.5443 - val_loss: 0.6872 - val_acc: 0.5511\n",
      "Epoch 3/8\n",
      "1288/1288 [==============================] - 1s 540us/step - loss: 0.6581 - acc: 0.6134 - val_loss: 0.6874 - val_acc: 0.5604\n",
      "Epoch 4/8\n",
      "1288/1288 [==============================] - 1s 575us/step - loss: 0.5994 - acc: 0.7492 - val_loss: 0.7194 - val_acc: 0.5480\n",
      "Epoch 5/8\n",
      "1288/1288 [==============================] - 1s 540us/step - loss: 0.5112 - acc: 0.7880 - val_loss: 0.7685 - val_acc: 0.5294\n",
      "Epoch 6/8\n",
      "1288/1288 [==============================] - 1s 542us/step - loss: 0.4171 - acc: 0.8370 - val_loss: 0.8430 - val_acc: 0.4985\n",
      "Epoch 7/8\n",
      "1288/1288 [==============================] - 1s 572us/step - loss: 0.3199 - acc: 0.8913 - val_loss: 0.9419 - val_acc: 0.5046\n",
      "Epoch 8/8\n",
      "1288/1288 [==============================] - 1s 558us/step - loss: 0.2253 - acc: 0.9464 - val_loss: 1.0701 - val_acc: 0.5108\n",
      "379/379 [==============================] - 0s 316us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_614 (Dense)            (None, 8)                 5264      \n",
      "_________________________________________________________________\n",
      "dropout_407 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_603 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_615 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_408 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_604 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_616 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_605 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,345\n",
      "Trainable params: 5,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/9\n",
      "1288/1288 [==============================] - 22s 17ms/step - loss: 0.6931 - acc: 0.5078 - val_loss: 0.6912 - val_acc: 0.5511\n",
      "Epoch 2/9\n",
      "1288/1288 [==============================] - 1s 427us/step - loss: 0.6905 - acc: 0.5582 - val_loss: 0.6896 - val_acc: 0.5511\n",
      "Epoch 3/9\n",
      "1288/1288 [==============================] - 0s 373us/step - loss: 0.6878 - acc: 0.5637 - val_loss: 0.6890 - val_acc: 0.5511\n",
      "Epoch 4/9\n",
      "1288/1288 [==============================] - 1s 403us/step - loss: 0.6844 - acc: 0.5668 - val_loss: 0.6879 - val_acc: 0.5480\n",
      "Epoch 5/9\n",
      "1288/1288 [==============================] - 0s 386us/step - loss: 0.6800 - acc: 0.5831 - val_loss: 0.6877 - val_acc: 0.5387\n",
      "Epoch 6/9\n",
      "1288/1288 [==============================] - 1s 400us/step - loss: 0.6712 - acc: 0.6351 - val_loss: 0.6862 - val_acc: 0.5387\n",
      "Epoch 7/9\n",
      "1288/1288 [==============================] - 0s 384us/step - loss: 0.6587 - acc: 0.6623 - val_loss: 0.6856 - val_acc: 0.5511\n",
      "Epoch 8/9\n",
      "1288/1288 [==============================] - 0s 386us/step - loss: 0.6474 - acc: 0.6809 - val_loss: 0.6863 - val_acc: 0.5387\n",
      "Epoch 9/9\n",
      "1288/1288 [==============================] - 1s 389us/step - loss: 0.6272 - acc: 0.6988 - val_loss: 0.6869 - val_acc: 0.5232\n",
      "379/379 [==============================] - 0s 297us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_617 (Dense)            (None, 16)                10528     \n",
      "_________________________________________________________________\n",
      "dropout_409 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_606 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_618 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_410 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "activation_607 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_619 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_608 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10,817\n",
      "Trainable params: 10,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/9\n",
      "1288/1288 [==============================] - 19s 14ms/step - loss: 0.6925 - acc: 0.5334 - val_loss: 0.6908 - val_acc: 0.5511\n",
      "Epoch 2/9\n",
      "1288/1288 [==============================] - 0s 369us/step - loss: 0.6873 - acc: 0.5380 - val_loss: 0.6892 - val_acc: 0.5511\n",
      "Epoch 3/9\n",
      "1288/1288 [==============================] - 0s 378us/step - loss: 0.6830 - acc: 0.5458 - val_loss: 0.6882 - val_acc: 0.5511\n",
      "Epoch 4/9\n",
      "1288/1288 [==============================] - 0s 382us/step - loss: 0.6763 - acc: 0.5598 - val_loss: 0.6877 - val_acc: 0.5604\n",
      "Epoch 5/9\n",
      "1288/1288 [==============================] - 0s 378us/step - loss: 0.6654 - acc: 0.5963 - val_loss: 0.6868 - val_acc: 0.5604\n",
      "Epoch 6/9\n",
      "1288/1288 [==============================] - 0s 370us/step - loss: 0.6428 - acc: 0.6545 - val_loss: 0.6894 - val_acc: 0.5387\n",
      "Epoch 7/9\n",
      "1288/1288 [==============================] - 1s 415us/step - loss: 0.6138 - acc: 0.7120 - val_loss: 0.6918 - val_acc: 0.5418\n",
      "Epoch 8/9\n",
      "1288/1288 [==============================] - 1s 408us/step - loss: 0.5765 - acc: 0.7484 - val_loss: 0.7050 - val_acc: 0.5356\n",
      "Epoch 9/9\n",
      "1288/1288 [==============================] - 1s 396us/step - loss: 0.5344 - acc: 0.7756 - val_loss: 0.7235 - val_acc: 0.5449\n",
      "379/379 [==============================] - 0s 282us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_620 (Dense)            (None, 24)                15792     \n",
      "_________________________________________________________________\n",
      "dropout_411 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_609 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_621 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_412 (Dropout)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "activation_610 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_622 (Dense)            (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "activation_611 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 16,417\n",
      "Trainable params: 16,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/9\n",
      "1288/1288 [==============================] - 20s 15ms/step - loss: 0.6926 - acc: 0.5202 - val_loss: 0.6895 - val_acc: 0.5511\n",
      "Epoch 2/9\n",
      "1288/1288 [==============================] - 1s 413us/step - loss: 0.6871 - acc: 0.5396 - val_loss: 0.6875 - val_acc: 0.5511\n",
      "Epoch 3/9\n",
      "1288/1288 [==============================] - 1s 412us/step - loss: 0.6784 - acc: 0.5474 - val_loss: 0.6853 - val_acc: 0.5511\n",
      "Epoch 4/9\n",
      "1288/1288 [==============================] - 1s 410us/step - loss: 0.6683 - acc: 0.5691 - val_loss: 0.6842 - val_acc: 0.5418\n",
      "Epoch 5/9\n",
      "1288/1288 [==============================] - 1s 406us/step - loss: 0.6439 - acc: 0.6576 - val_loss: 0.6819 - val_acc: 0.5635\n",
      "Epoch 6/9\n",
      "1288/1288 [==============================] - 1s 424us/step - loss: 0.6081 - acc: 0.7236 - val_loss: 0.6901 - val_acc: 0.5449\n",
      "Epoch 7/9\n",
      "1288/1288 [==============================] - 1s 390us/step - loss: 0.5564 - acc: 0.7772 - val_loss: 0.7093 - val_acc: 0.5542\n",
      "Epoch 8/9\n",
      "1288/1288 [==============================] - 1s 409us/step - loss: 0.4938 - acc: 0.8160 - val_loss: 0.7422 - val_acc: 0.5232\n",
      "Epoch 9/9\n",
      "1288/1288 [==============================] - 1s 396us/step - loss: 0.4346 - acc: 0.8377 - val_loss: 0.7865 - val_acc: 0.5139\n",
      "379/379 [==============================] - 0s 289us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_623 (Dense)            (None, 32)                21056     \n",
      "_________________________________________________________________\n",
      "dropout_413 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_612 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_624 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_414 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_613 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_625 (Dense)            (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_614 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 22,145\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/9\n",
      "1288/1288 [==============================] - 19s 15ms/step - loss: 0.6912 - acc: 0.5295 - val_loss: 0.6890 - val_acc: 0.5511\n",
      "Epoch 2/9\n",
      "1288/1288 [==============================] - 1s 490us/step - loss: 0.6846 - acc: 0.5481 - val_loss: 0.6866 - val_acc: 0.5511\n",
      "Epoch 3/9\n",
      "1288/1288 [==============================] - 1s 465us/step - loss: 0.6771 - acc: 0.5567 - val_loss: 0.6858 - val_acc: 0.5418\n",
      "Epoch 4/9\n",
      "1288/1288 [==============================] - 1s 489us/step - loss: 0.6562 - acc: 0.6537 - val_loss: 0.6858 - val_acc: 0.5511\n",
      "Epoch 5/9\n",
      "1288/1288 [==============================] - 1s 492us/step - loss: 0.6205 - acc: 0.6972 - val_loss: 0.6930 - val_acc: 0.5170\n",
      "Epoch 6/9\n",
      "1288/1288 [==============================] - 1s 482us/step - loss: 0.5621 - acc: 0.7562 - val_loss: 0.7172 - val_acc: 0.5170\n",
      "Epoch 7/9\n",
      "1288/1288 [==============================] - 1s 479us/step - loss: 0.4993 - acc: 0.7943 - val_loss: 0.7505 - val_acc: 0.5294\n",
      "Epoch 8/9\n",
      "1288/1288 [==============================] - 1s 471us/step - loss: 0.4358 - acc: 0.8222 - val_loss: 0.8024 - val_acc: 0.5232\n",
      "Epoch 9/9\n",
      "1288/1288 [==============================] - 1s 483us/step - loss: 0.3699 - acc: 0.8711 - val_loss: 0.8641 - val_acc: 0.5232\n",
      "379/379 [==============================] - 0s 284us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_626 (Dense)            (None, 40)                26320     \n",
      "_________________________________________________________________\n",
      "dropout_415 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_615 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_627 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_416 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_616 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_628 (Dense)            (None, 1)                 41        \n",
      "_________________________________________________________________\n",
      "activation_617 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,001\n",
      "Trainable params: 28,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288/1288 [==============================] - 20s 16ms/step - loss: 0.6918 - acc: 0.5264 - val_loss: 0.6888 - val_acc: 0.5511\n",
      "Epoch 2/9\n",
      "1288/1288 [==============================] - 1s 486us/step - loss: 0.6842 - acc: 0.5404 - val_loss: 0.6877 - val_acc: 0.5511\n",
      "Epoch 3/9\n",
      "1288/1288 [==============================] - 1s 488us/step - loss: 0.6733 - acc: 0.5691 - val_loss: 0.6879 - val_acc: 0.5480\n",
      "Epoch 4/9\n",
      "1288/1288 [==============================] - 1s 486us/step - loss: 0.6486 - acc: 0.6110 - val_loss: 0.6880 - val_acc: 0.5263\n",
      "Epoch 5/9\n",
      "1288/1288 [==============================] - 1s 476us/step - loss: 0.6054 - acc: 0.7158 - val_loss: 0.6974 - val_acc: 0.5387\n",
      "Epoch 6/9\n",
      "1288/1288 [==============================] - 1s 490us/step - loss: 0.5330 - acc: 0.7919 - val_loss: 0.7354 - val_acc: 0.5294\n",
      "Epoch 7/9\n",
      "1288/1288 [==============================] - 1s 471us/step - loss: 0.4443 - acc: 0.8385 - val_loss: 0.7951 - val_acc: 0.5108\n",
      "Epoch 8/9\n",
      "1288/1288 [==============================] - 1s 471us/step - loss: 0.3668 - acc: 0.8750 - val_loss: 0.8550 - val_acc: 0.5108\n",
      "Epoch 9/9\n",
      "1288/1288 [==============================] - 1s 475us/step - loss: 0.2811 - acc: 0.9247 - val_loss: 0.9956 - val_acc: 0.5046\n",
      "379/379 [==============================] - 0s 297us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_629 (Dense)            (None, 48)                31584     \n",
      "_________________________________________________________________\n",
      "dropout_417 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_618 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_630 (Dense)            (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dropout_418 (Dropout)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "activation_619 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_631 (Dense)            (None, 1)                 49        \n",
      "_________________________________________________________________\n",
      "activation_620 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33,985\n",
      "Trainable params: 33,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/9\n",
      "1288/1288 [==============================] - 22s 17ms/step - loss: 0.6928 - acc: 0.5280 - val_loss: 0.6893 - val_acc: 0.5511\n",
      "Epoch 2/9\n",
      "1288/1288 [==============================] - 1s 536us/step - loss: 0.6830 - acc: 0.5411 - val_loss: 0.6892 - val_acc: 0.5511\n",
      "Epoch 3/9\n",
      "1288/1288 [==============================] - 1s 585us/step - loss: 0.6706 - acc: 0.5637 - val_loss: 0.6903 - val_acc: 0.5511\n",
      "Epoch 4/9\n",
      "1288/1288 [==============================] - 1s 520us/step - loss: 0.6412 - acc: 0.6545 - val_loss: 0.6960 - val_acc: 0.5139\n",
      "Epoch 5/9\n",
      "1288/1288 [==============================] - 1s 592us/step - loss: 0.5814 - acc: 0.7368 - val_loss: 0.7146 - val_acc: 0.5294\n",
      "Epoch 6/9\n",
      "1288/1288 [==============================] - 1s 531us/step - loss: 0.4970 - acc: 0.7966 - val_loss: 0.7599 - val_acc: 0.4985\n",
      "Epoch 7/9\n",
      "1288/1288 [==============================] - 1s 582us/step - loss: 0.4015 - acc: 0.8486 - val_loss: 0.8317 - val_acc: 0.4985\n",
      "Epoch 8/9\n",
      "1288/1288 [==============================] - 1s 542us/step - loss: 0.3131 - acc: 0.8998 - val_loss: 0.9406 - val_acc: 0.5139\n",
      "Epoch 9/9\n",
      "1288/1288 [==============================] - 1s 536us/step - loss: 0.2343 - acc: 0.9325 - val_loss: 1.0229 - val_acc: 0.4985\n",
      "379/379 [==============================] - 0s 332us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_632 (Dense)            (None, 56)                36848     \n",
      "_________________________________________________________________\n",
      "dropout_419 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_621 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_633 (Dense)            (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dropout_420 (Dropout)        (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "activation_622 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_634 (Dense)            (None, 1)                 57        \n",
      "_________________________________________________________________\n",
      "activation_623 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,097\n",
      "Trainable params: 40,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/9\n",
      "1288/1288 [==============================] - 23s 18ms/step - loss: 0.6914 - acc: 0.5264 - val_loss: 0.6890 - val_acc: 0.5511\n",
      "Epoch 2/9\n",
      "1288/1288 [==============================] - 1s 540us/step - loss: 0.6849 - acc: 0.5388 - val_loss: 0.6876 - val_acc: 0.5511\n",
      "Epoch 3/9\n",
      "1288/1288 [==============================] - 1s 544us/step - loss: 0.6726 - acc: 0.5505 - val_loss: 0.6863 - val_acc: 0.5604\n",
      "Epoch 4/9\n",
      "1288/1288 [==============================] - 1s 565us/step - loss: 0.6459 - acc: 0.6599 - val_loss: 0.6901 - val_acc: 0.5325\n",
      "Epoch 5/9\n",
      "1288/1288 [==============================] - 1s 576us/step - loss: 0.5877 - acc: 0.7329 - val_loss: 0.7109 - val_acc: 0.5263\n",
      "Epoch 6/9\n",
      "1288/1288 [==============================] - 1s 539us/step - loss: 0.5041 - acc: 0.7904 - val_loss: 0.7611 - val_acc: 0.5294\n",
      "Epoch 7/9\n",
      "1288/1288 [==============================] - 1s 592us/step - loss: 0.4182 - acc: 0.8393 - val_loss: 0.8540 - val_acc: 0.5201\n",
      "Epoch 8/9\n",
      "1288/1288 [==============================] - 1s 630us/step - loss: 0.3332 - acc: 0.8773 - val_loss: 0.9345 - val_acc: 0.5139\n",
      "Epoch 9/9\n",
      "1288/1288 [==============================] - 1s 668us/step - loss: 0.2682 - acc: 0.9224 - val_loss: 1.0510 - val_acc: 0.5108\n",
      "379/379 [==============================] - 0s 376us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_635 (Dense)            (None, 64)                42112     \n",
      "_________________________________________________________________\n",
      "dropout_421 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_624 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_636 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_422 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_625 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_637 (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_626 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 46,337\n",
      "Trainable params: 46,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1288 samples, validate on 323 samples\n",
      "Epoch 1/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288/1288 [==============================] - 20s 15ms/step - loss: 0.6930 - acc: 0.5202 - val_loss: 0.6888 - val_acc: 0.5511\n",
      "Epoch 2/9\n",
      "1288/1288 [==============================] - 1s 609us/step - loss: 0.6826 - acc: 0.5404 - val_loss: 0.6876 - val_acc: 0.5511\n",
      "Epoch 3/9\n",
      "1288/1288 [==============================] - 1s 604us/step - loss: 0.6731 - acc: 0.5606 - val_loss: 0.6850 - val_acc: 0.5635\n",
      "Epoch 4/9\n",
      "1288/1288 [==============================] - 1s 594us/step - loss: 0.6431 - acc: 0.6530 - val_loss: 0.6887 - val_acc: 0.5418\n",
      "Epoch 5/9\n",
      "1288/1288 [==============================] - 1s 593us/step - loss: 0.5715 - acc: 0.7547 - val_loss: 0.7113 - val_acc: 0.5666\n",
      "Epoch 6/9\n",
      "1288/1288 [==============================] - 1s 656us/step - loss: 0.4809 - acc: 0.7974 - val_loss: 0.7690 - val_acc: 0.5263\n",
      "Epoch 7/9\n",
      "1288/1288 [==============================] - 1s 776us/step - loss: 0.3704 - acc: 0.8556 - val_loss: 0.8663 - val_acc: 0.5170\n",
      "Epoch 8/9\n",
      "1288/1288 [==============================] - 1s 859us/step - loss: 0.2850 - acc: 0.9099 - val_loss: 0.9865 - val_acc: 0.5170\n",
      "Epoch 9/9\n",
      "1288/1288 [==============================] - 1s 832us/step - loss: 0.1930 - acc: 0.9596 - val_loss: 1.1111 - val_acc: 0.5077\n",
      "379/379 [==============================] - 0s 432us/step\n"
     ]
    }
   ],
   "source": [
    "epochs = np.arange(1, 10, 1)\n",
    "dense = np.arange(8, 65, 8)\n",
    "models = []\n",
    "acc_result = []\n",
    "for i in epochs:\n",
    "    for j in dense:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(j,input_shape=(biTrain.shape[1],)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(j))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        model.summary()\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc'])\n",
    "        model.fit(biTrain,train['Label'],batch_size=32,epochs=i,verbose=1,validation_split=0.2)\n",
    "        test_loss, test_acc = model.evaluate(biTest, test['Label'])\n",
    "        models.append(model)\n",
    "        acc_result.append({'epochs': i, 'dense': j, 'test accuracy': test_acc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dense</th>\n",
       "      <th>epochs</th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>0.575198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dense  epochs  test accuracy\n",
       "46     56       6       0.575198"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_result[acc_result['test accuracy'] == max(acc_result['test accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dense</th>\n",
       "      <th>epochs</th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.532982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.503958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.509235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>0.538259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.527704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.511873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0.517150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.535620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.525066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>0.517150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.556728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.559367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>0.546174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>0.572559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>0.575198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>0.559367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.551451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.556728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.548813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.567282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>0.548813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>0.551451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>0.554090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.546174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.538259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.567282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>0.535620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.569921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.564644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>0.548813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>0.538259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>0.546174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.532982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0.527704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0.564644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>0.551451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>0.538259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>0.527704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>0.546174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>0.532982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dense  epochs  test accuracy\n",
       "0       8       1       0.503958\n",
       "1      16       1       0.501319\n",
       "2      24       1       0.506596\n",
       "3      32       1       0.506596\n",
       "4      40       1       0.506596\n",
       "5      48       1       0.506596\n",
       "6      56       1       0.503958\n",
       "7      64       1       0.506596\n",
       "8       8       2       0.532982\n",
       "9      16       2       0.506596\n",
       "10     24       2       0.506596\n",
       "11     32       2       0.506596\n",
       "12     40       2       0.506596\n",
       "13     48       2       0.506596\n",
       "14     56       2       0.506596\n",
       "15     64       2       0.503958\n",
       "16      8       3       0.506596\n",
       "17     16       3       0.509235\n",
       "18     24       3       0.506596\n",
       "19     32       3       0.506596\n",
       "20     40       3       0.506596\n",
       "21     48       3       0.506596\n",
       "22     56       3       0.538259\n",
       "23     64       3       0.527704\n",
       "24      8       4       0.506596\n",
       "25     16       4       0.511873\n",
       "26     24       4       0.517150\n",
       "27     32       4       0.535620\n",
       "28     40       4       0.525066\n",
       "29     48       4       0.517150\n",
       "..    ...     ...            ...\n",
       "42     24       6       0.556728\n",
       "43     32       6       0.559367\n",
       "44     40       6       0.546174\n",
       "45     48       6       0.572559\n",
       "46     56       6       0.575198\n",
       "47     64       6       0.559367\n",
       "48      8       7       0.551451\n",
       "49     16       7       0.556728\n",
       "50     24       7       0.548813\n",
       "51     32       7       0.567282\n",
       "52     40       7       0.548813\n",
       "53     48       7       0.551451\n",
       "54     56       7       0.554090\n",
       "55     64       7       0.546174\n",
       "56      8       8       0.538259\n",
       "57     16       8       0.567282\n",
       "58     24       8       0.535620\n",
       "59     32       8       0.569921\n",
       "60     40       8       0.564644\n",
       "61     48       8       0.548813\n",
       "62     56       8       0.538259\n",
       "63     64       8       0.546174\n",
       "64      8       9       0.532982\n",
       "65     16       9       0.527704\n",
       "66     24       9       0.564644\n",
       "67     32       9       0.551451\n",
       "68     40       9       0.538259\n",
       "69     48       9       0.527704\n",
       "70     56       9       0.546174\n",
       "71     64       9       0.532982\n",
       "\n",
       "[72 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e517045b70>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e51717c860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_result = pd.DataFrame(acc_result)\n",
    "sns.set(rc={'figure.figsize':(16, 8)})\n",
    "sns.scatterplot(x='epochs', y='dense', hue=\"test accuracy\", size=\"test accuracy\",data=acc_result, sizes=(10, 500))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
